"""
æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†çš„Agentç±»
å®ç°tokenç›‘æ§ã€HCAå†å²è®°å½•å’Œè‡ªåŠ¨æˆªæ–­åŠŸèƒ½
"""

from typing import Optional, Dict, Any, List, Union, Callable, Iterator, Tuple, Type, AsyncIterator, Sequence
import json
from datetime import datetime
from agno.agent import Agent
from agno.models.base import Model
from agno.models.response import ModelResponse
from agno.models.message import Message
from agno.run.response import RunResponse
from agno.tools import tool
from agno.utils.log import logger, set_log_level_to_debug  # ä½¿ç”¨Agnoçš„loggerç³»ç»Ÿ
from pydantic import BaseModel
from agno.media import Audio, Image, Video, File
import time
import threading


class ContextManagedAgent(Agent):
    """
    é‡å†™çš„Agentç±»ï¼Œå®ç°æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. Tokenä½¿ç”¨ç›‘æ§ (70%æé†’, 80%æˆªæ–­)
    2. HCAå†å²è®°å½•å®Œæ•´ä¿å­˜
    3. æ™ºèƒ½æ¶ˆæ¯æˆªæ–­ (ä¿ç•™50%æœ€æ–°å†…å®¹)
    4. ä¸Šä¸‹æ–‡è¿›åº¦æé†’
    5. å¯é…ç½®çš„å·¥å…·è°ƒç”¨é˜»æ–­é˜ˆå€¼
    
    å¯é…ç½®å‚æ•°ï¼š
    - max_context_tokens: æœ€å¤§ä¸Šä¸‹æ–‡tokenæ•°ï¼Œé»˜è®¤25000
    - warning_threshold: è­¦å‘Šé˜ˆå€¼ï¼ˆæ¯”ä¾‹ï¼‰ï¼Œé»˜è®¤0.7ï¼ˆ70%ï¼‰
    - truncate_threshold: æˆªæ–­é˜ˆå€¼ï¼ˆæ¯”ä¾‹ï¼‰ï¼Œé»˜è®¤0.8ï¼ˆ80%ï¼‰
    - tool_block_threshold: å·¥å…·è°ƒç”¨é˜»æ–­é˜ˆå€¼ï¼ˆæ¯”ä¾‹ï¼‰ï¼Œé»˜è®¤0.85ï¼ˆ85%ï¼‰
    - keep_ratio: æˆªæ–­æ—¶ä¿ç•™æ¶ˆæ¯çš„æ¯”ä¾‹ï¼Œé»˜è®¤0.5ï¼ˆ50%ï¼‰
    - summary_max_chars: æ‘˜è¦æ¶ˆæ¯æœ€å¤§å­—ç¬¦æ•°ï¼Œé»˜è®¤1200
    """
    
    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–ContextManagedAgent"""
        # ä½¿ç”¨å¤šç§æ–¹å¼ç¡®ä¿è°ƒè¯•ä¿¡æ¯èƒ½è¢«çœ‹åˆ°
        print("=" * 80)
        print("ğŸ¯ ContextManagedAgent.__init__ å¼€å§‹!")
        print("=" * 80)
        
        # ä½¿ç”¨æ ‡å‡†loggingè€Œä¸æ˜¯loguru
        import logging
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)
        
        self.max_context_tokens = kwargs.pop('max_context_tokens', 25000)
        self.warning_threshold = kwargs.pop('warning_threshold', 0.7)
        self.truncate_threshold = kwargs.pop('truncate_threshold', 0.8)
        self.keep_ratio = kwargs.pop('keep_ratio', 0.5)
        # ğŸ”¥ æ–°å¢ï¼šå·¥å…·è°ƒç”¨é˜»æ–­é˜ˆå€¼ï¼Œé»˜è®¤85%ï¼Œè¶…è¿‡æ­¤é˜ˆå€¼ä¼šè¦æ±‚å…ˆå‹ç¼©ä¸Šä¸‹æ–‡
        self.tool_block_threshold = kwargs.pop('tool_block_threshold', 0.85)
        
        # -------  æ–°å¢: tool æ¶ˆæ¯å‹ç¼© / ä¸¢å¼ƒç­–ç•¥å¯è°ƒå‚æ•°  -------
        # ä¿ç•™æœ€è¿‘ N æ¡ tool æ¶ˆæ¯çš„å®Œæ•´æ­£æ–‡ï¼Œå…¶ä½™å¯è¢«å‹ç¼©æˆ–åˆ é™¤
        self.keep_recent_tool_messages = kwargs.pop('keep_recent_tool_messages', 2)
        # å‹ç¼©å tool æ¶ˆæ¯æœ€å¤§å­—ç¬¦æ•° (â‰ˆ token Ã—2)
        self.max_tool_message_chars = kwargs.pop('max_tool_message_chars', 1200)
        # ---- æ–°å¢: æ‘˜è¦æ¶ˆæ¯æœ€å¤§é•¿åº¦ï¼Œå¯é€šè¿‡æ„é€ å‚æ•° summary_max_chars è°ƒæ•´ ----
        self.summary_max_chars = kwargs.pop('summary_max_chars', 1200)
        # æ˜¯å¦ä¿ç•™æ—§ç‰ˆ _ai_summarize_history_with_context_protection æµç¨‹
        self.use_legacy_summary = kwargs.pop('use_legacy_summary', False)
        
        logger.critical(f"ğŸ¯ ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®:")
        logger.critical(f"   max_context_tokens: {self.max_context_tokens}")
        logger.critical(f"   warning_threshold: {self.warning_threshold*100:.1f}%")
        logger.critical(f"   truncate_threshold: {self.truncate_threshold*100:.1f}%")
        logger.critical(f"   tool_block_threshold: {self.tool_block_threshold*100:.1f}%")
        logger.critical(f"   keep_ratio: {self.keep_ratio*100:.1f}%")
        
        # åˆå§‹åŒ–çŠ¶æ€
        self._warning_sent = False
        self._last_warning_sent = False
        self._last_run_token_usage = 0  # è®°å½•ä¸Šä¸€æ¬¡è¿è¡Œçš„tokenä½¿ç”¨é‡
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        logger.critical(f"ğŸ¯ è°ƒç”¨super().__init__...")
        super().__init__(*args, **kwargs)
        logger.critical(f"ğŸ¯ super().__init__å®Œæˆ!")
        
        # v1.6+ ç‰ˆæœ¬é€šè¿‡ RunResponse.metrics æä¾›å®Œæ•´ token/cost æ•°æ®ï¼Œ
        # å·²ä¸éœ€è¦ monkey-patch æ¨¡å‹æ–¹æ³•ï¼›ä¿ç•™æ—¥å¿—ï¼Œè¯´æ˜å·²è·³è¿‡ã€‚
        if hasattr(self, 'model') and self.model:
            logger.debug("ğŸ”§ è·³è¿‡ _patch_model_methodsï¼Œç›´æ¥ä½¿ç”¨ metrics")
        else:
            logger.debug("ğŸ”§ æ—  model å¯ç”¨ï¼Œäº¦æ— éœ€æ‰“è¡¥ä¸")
        
        # åˆå§‹åŒ–session_state
        if not hasattr(self, 'session_state'):
            self.session_state = {}
            
        # ç¡®ä¿ä¸Šä¸‹æ–‡ç®¡ç†çŠ¶æ€å­˜åœ¨å¹¶åˆå§‹åŒ–æ‰€æœ‰å¿…è¦å­—æ®µ
        if self.session_state is None:
            self.session_state = {}
        if 'context_management' not in self.session_state:
            self.session_state['context_management'] = {}
            
        context_management = self.session_state['context_management']
        # ä½¿ç”¨å­—å…¸çš„getæ–¹æ³•è®¾ç½®é»˜è®¤å€¼ï¼Œè¿™æ ·ä¸ä¼šè¦†ç›–å·²æœ‰çš„å€¼
        context_management.setdefault('warning_sent', False)
        context_management.setdefault('last_warning_sent', False)
        context_management.setdefault('total_tokens_calculated', 0)
        context_management.setdefault('truncations_performed', 0)
        context_management.setdefault('last_calculation_time', None)
        context_management.setdefault('last_run_token_usage', 0)
        context_management.setdefault('truncation_count', 0)
        
        # ç¡®ä¿session_stateä¸­æœ‰HCAå†å²è®°å½•ç»“æ„
        self._ensure_hca_history_structure()
        
        # æ·»åŠ HCAæŸ¥è¯¢å·¥å…·
        self._add_hca_tools()
        
        # æ·»åŠ å…¨å±€Message.logè¡¥ä¸ï¼Œç¡®ä¿æ‰€æœ‰assistantæ—¥å¿—éƒ½ä¼šè§¦å‘tokenç›‘æ§
        self._patch_message_log()
        
        # è¿è¡ŒæœŸæ¶ˆæ¯ç¼“å†²ï¼Œæ”¯æŒå•è½® run å†…å³æ—¶æˆªæ–­
        self._live_messages: List[Message] = []
        # TODO(ä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–): è®¡åˆ’åç»­å®Œå…¨ç§»é™¤ _live_messages ç¼“å†²åŒºï¼Œç›´æ¥ç»Ÿä¸€æ“ä½œ run_messages.messagesï¼Œä»¥ç®€åŒ–é€»è¾‘å¹¶é¿å…æ•°æ®æ¥æºæ··ä¹±ã€‚

        # ------------------------------------------------------------------
        # ğŸ› ï¸  æ–°å¢: tool æ¶ˆæ¯å‹ç¼© / ä¸¢å¼ƒ è¾…åŠ©æ–¹æ³•
        # ------------------------------------------------------------------

        def _capture_tool_result(function_name: str, next_func: Callable, arguments: Dict[str, Any]):  # type: ignore
            """Agno tool_hook: è®°å½•å·¥å…·è°ƒç”¨ç»“æœ"""
            logger.debug(f"ğŸ”§ capture_tool_result: æ‰§è¡Œå·¥å…· {function_name} args={arguments}")

            # ğŸ‘‰ è‹¥å½“å‰æ‰§è¡Œçš„å·¥å…·å°±æ˜¯ summarize_contextï¼Œåˆ™ç›´æ¥æ”¾è¡Œï¼Œä¸åšè¶…é™æ‹¦æˆª
            if function_name == "summarize_context":
                try:
                    return next_func(**(arguments or {}))
                except Exception as _tool_err:
                    logger.error(f"âŒ summarize_context æ‰§è¡Œå¤±è´¥: {_tool_err}")
                    raise

            # ğŸ‘‰ å¯¹å…¶å®ƒå·¥å…·è¿›è¡Œä¸Šä¸‹æ–‡è¶…é™æ£€æŸ¥
            try:
                agent_obj = None
                if isinstance(arguments, dict):
                    agent_obj = arguments.get("agent")
                if agent_obj is None:
                    # è‹¥å·¥å…·å‡½æ•°ç­¾åä¸å« agent å‚æ•°ï¼Œåˆ™ç›´æ¥ä½¿ç”¨é—­åŒ…ä¸­çš„ self
                    agent_obj = self
                if hasattr(agent_obj, "_get_actual_token_usage"):
                    usage = agent_obj._get_actual_token_usage(is_new_run=True)

                    # ğŸ”„ è‹¥å½“å‰ run å°šæœªå®Œæˆï¼Œmetrics å¯èƒ½å–ä¸åˆ°ï¼›æ”¹ç”¨ session_state çš„ä¸Šä¸€æ¬¡å€¼
                    if usage.get("total_tokens", 0) == 0:
                        cm = agent_obj.session_state.get("context_management", {})
                        last_tokens = cm.get("last_run_token_usage", 0)
                        usage["total_tokens"] = last_tokens
                        usage["usage_percentage"] = (
                            (last_tokens / agent_obj.max_context_tokens) * 100
                            if agent_obj.max_context_tokens > 0 else 0.0
                        )

                    # ğŸ”¥ ä½¿ç”¨å¯é…ç½®çš„å·¥å…·è°ƒç”¨é˜»æ–­é˜ˆå€¼ï¼Œé¿å…æ— é™å·¥å…·è°ƒç”¨å¾ªç¯
                    if usage.get("usage_percentage", 0) >= (agent_obj.tool_block_threshold * 100):
                        limit_chars = getattr(agent_obj, "summary_max_chars", 1200)
                        
                        # ç›´æ¥è¦æ±‚æ‘˜è¦ï¼Œä¸ä½¿ç”¨å»¶è¿Ÿæˆªæ–­
                        return (
                            f"âŒ å½“å‰ä¸Šä¸‹æ–‡å·²ä½¿ç”¨ {usage['usage_percentage']:.1f}% "
                            f"({usage['total_tokens']}/{agent_obj.max_context_tokens})ï¼Œä¸ºä¿è¯åç»­åˆ†æï¼Œè¯·å…ˆè°ƒç”¨\n"
                            f"summarize_context(summary=\"<ä¸è¶…è¿‡{limit_chars}å­—çš„å¯¹è¯æ‘˜è¦>\") å‹ç¼©ä¸Šä¸‹æ–‡åå†é‡è¯•æœ¬å·¥å…·ã€‚"
                        )
            except Exception as _chk_err:
                logger.debug(f"âš ï¸ è¶…é™æ£€æŸ¥å¤±è´¥: {_chk_err}")

            # æ‰§è¡ŒåŸå·¥å…·å¹¶è·å–åŸå§‹ç»“æœ
            raw_result = next_func(**(arguments or {}))  # æ‰§è¡ŒåŸå·¥å…·

            try:
                raw_str = str(raw_result)
                logger.debug(f"ğŸ”§ capture_tool_result: å·¥å…· {function_name} è¿”å›é•¿åº¦ {len(raw_str)} å­—ç¬¦")
            except Exception:
                logger.debug(f"ğŸ”§ capture_tool_result: å·¥å…· {function_name} è¿”å›ä¸å¯åºåˆ—åŒ–ç»“æœ")

            # è¿”å›åŸå§‹ç»“æœï¼Œä¸æˆªæ–­ï¼ˆè®©æœ€æ–°çš„å·¥å…·è°ƒç”¨ä¿æŒå®Œæ•´ï¼‰
            return raw_result

        # æ³¨å†Œåˆ° agent çš„ tool_hooks åˆ—è¡¨
        if not hasattr(self, "tool_hooks") or self.tool_hooks is None:
            self.tool_hooks = []
        self.tool_hooks.append(_capture_tool_result)

        # ---- å°† hook ç»‘å®šåˆ°å·²æ³¨å†Œçš„æ‰€æœ‰ tool / Toolkit.Function ----
        try:
            from agno.tools.function import Function as _AgnoFunction  # type: ignore

            for _t in (self.tools or []):
                try:
                    # è‹¥ä¸º Toolkitï¼Œéå†å†…éƒ¨ functions (dict.values)
                    if hasattr(_t, "functions") and isinstance(getattr(_t, "functions"), dict):
                        for _fname, _f in _t.functions.items():  # type: ignore
                            if isinstance(_f, _AgnoFunction):
                                _f.tool_hooks = (_f.tool_hooks or []) + [_capture_tool_result]
                    # Toolkit.functions è‹¥ä¸º listï¼ˆå…¼å®¹è€ç‰ˆæœ¬ï¼‰
                    elif hasattr(_t, "functions") and isinstance(getattr(_t, "functions"), list):
                        for _f in _t.functions:  # type: ignore
                            if isinstance(_f, _AgnoFunction):
                                _f.tool_hooks = (_f.tool_hooks or []) + [_capture_tool_result]
                    # å•ä¸ª Function æˆ– @tool åŒ…è£…åçš„å¯¹è±¡
                    elif isinstance(_t, _AgnoFunction):
                        _t.tool_hooks = (_t.tool_hooks or []) + [_capture_tool_result]
                except Exception as _bind_err:  # pragma: no cover
                    logger.debug(f"âš ï¸ ç»‘å®š tool_hook å¤±è´¥: {_bind_err}")
        except Exception:
            pass
    
    def _ensure_hca_history_structure(self):
        """ç¡®ä¿session_stateä¸­æœ‰å®Œæ•´çš„HCAå†å²è®°å½•ç»“æ„"""
        if not hasattr(self, 'session_state') or self.session_state is None:
            self.session_state = {}
        
        if self.session_state is None:
            self.session_state = {}
        if 'hca_complete_history' not in self.session_state:
            self.session_state['hca_complete_history'] = []
        
        if 'context_management' not in self.session_state:
            self.session_state['context_management'] = {
                'truncation_count': 0,
                'last_truncation_time': None,
                'total_tokens_processed': 0
            }
    
    def _add_hca_tools(self):
        """æ·»åŠ HCAå†å²æŸ¥è¯¢å·¥å…·"""
        
        @tool
        def query_hca_history(agent: ContextManagedAgent, keyword: str = "", tail: int = 10) -> str:
            """
            æŸ¥è¯¢HCAå†å²è®°å½•
            
            Args:
                keyword: æœç´¢å…³é”®è¯ï¼Œä¸ºç©ºåˆ™æ˜¾ç¤ºæ‰€æœ‰è®°å½•
                tail: æ˜¾ç¤ºæœ€è¿‘Næ¡è®°å½•ï¼Œé»˜è®¤10æ¡ï¼Œè®¾ä¸º-1æ˜¾ç¤ºå…¨éƒ¨
            """
            history = agent.session_state.get('hca_complete_history', [])
            
            if not history:
                return "ğŸ“š **HCAå†å²è®°å½•**: æš‚æ— è®°å½•"
            
            # å¦‚æœæœ‰å…³é”®è¯ï¼Œå…ˆè¿‡æ»¤
            if keyword.strip():
                filtered_history = []
                keyword_lower = keyword.lower()
                for record in history:
                    # åœ¨æ‰€æœ‰å­—æ®µä¸­æœç´¢å…³é”®è¯
                    searchable_text = f"{record.get('hypothesis', '')} {record.get('challenge', '')} {record.get('adaptation', '')} {record.get('evidence', '')}".lower()
                    if keyword_lower in searchable_text:
                        filtered_history.append(record)
                history = filtered_history
                
                if not history:
                    return f"ğŸ“š **HCAå†å²è®°å½•**: æœªæ‰¾åˆ°åŒ…å«'{keyword}'çš„è®°å½•"
            
            # ç¡®å®šæ˜¾ç¤ºèŒƒå›´
            if tail == -1:
                display_history = history
                title = f"ğŸ“š **å®Œæ•´HCAå†å²è®°å½•** (å…±{len(history)}æ¡)"
            else:
                display_history = history[-tail:] if len(history) > tail else history
                title = f"ğŸ“š **æœ€è¿‘{len(display_history)}æ¡HCAè®°å½•** (å…±{len(history)}æ¡)"
            
            if keyword.strip():
                title = f"ğŸ“š **åŒ…å«'{keyword}'çš„HCAè®°å½•** (å…±{len(display_history)}æ¡)"
            
            result = f"{title}\n\n"
            
            for i, record in enumerate(display_history, 1):
                result += f"**{record.get('id', f'#{i}')}** - {record.get('timestamp', 'N/A')}\n"
                result += f"- å‡è®¾: {record.get('hypothesis', 'N/A')}\n"
                result += f"- æŒ‘æˆ˜: {record.get('challenge', 'N/A')}\n"
                result += f"- é€‚åº”: {record.get('adaptation', 'N/A')}\n"
                result += f"- çŠ¶æ€: {record.get('status', 'N/A')}\n"
                if record.get('evidence'):
                    result += f"- è¯æ®: {record.get('evidence')[:100]}...\n"
                result += "---\n"
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            completed = len([r for r in history if r.get('status') == 'completed'])
            result += f"\nğŸ“Š **ç»Ÿè®¡**: æ€»è®¡{len(history)}æ¡ï¼Œå·²å®Œæˆ{completed}æ¡"
            
            return result
        
        # å°†å·¥å…·æ·»åŠ åˆ°agent
        if not hasattr(self, 'tools') or self.tools is None:
            self.tools = []
        elif not isinstance(self.tools, list):
            self.tools = list(self.tools) if self.tools else []
        self.tools.append(query_hca_history)
        
        # ä¿å­˜å·¥å…·å‡½æ•°çš„å¼•ç”¨
        self._hca_query_tool = query_hca_history

        # ------------------------------------------------------------------
        # âœ¨ æ–°å¢: ä¸Šä¸‹æ–‡æ‘˜è¦å·¥å…·
        # ------------------------------------------------------------------

        @tool
        def summarize_context(agent: ContextManagedAgent, summary: str) -> str:
            """âš™ï¸ **ä¸Šä¸‹æ–‡å‹ç¼©å·¥å…·**

            ç”¨é€”ï¼šåœ¨å¯¹è¯ token å ç”¨ç‡æ¥è¿‘ä¸Šé™æ—¶ï¼Œç”± LLM è°ƒç”¨æœ¬å·¥å…·æäº¤ *ç®€è¦æ‘˜è¦* ä»¥æ›¿æ¢è¿‡å¾€å†—é•¿å¯¹è¯ã€‚

            çº¦æŸï¼š
            1. å…¥å‚å¿…é¡»ä¸º JSON æ ¼å¼ï¼Œå¦‚ï¼š`{"summary": "è¿™é‡Œæ˜¯ä¸è¶…è¿‡ N å­—çš„æ€»ç»“"}`
            2. æ€»ç»“åº”ä¸“æ³¨äº**å¯¹è¯è¦ç‚¹**ä¸**é˜¶æ®µæ€§ç»“è®º**ï¼Œé¿å…ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚
            3. å­—æ•° â‰¤ `agent.summary_max_chars`ï¼ˆé»˜è®¤ 1200ï¼‰ã€‚
            """

            max_len = getattr(agent, "summary_max_chars", 1200)

            # åŸºç¡€æ ¡éªŒï¼šæ‘˜è¦ä¸å¾—è¿‡é•¿
            if len(summary) > max_len:
                return f"âŒ æ‘˜è¦è¿‡é•¿ï¼Œè¯·å‹ç¼©åˆ° {max_len} å­—ä»¥å†…å†é‡è¯•"

            from agno.models.message import Message

            # ç¡®ä¿ messages å®¹å™¨å­˜åœ¨
            if not hasattr(agent, "messages") or agent.messages is None:
                # å°è¯•å›é€€åˆ° _live_messages
                fallback_msgs = list(getattr(agent, "_live_messages", []))
                agent.messages = fallback_msgs

            if not isinstance(agent.messages, list):
                # è‹¥ messages ç±»å‹å¼‚å¸¸ï¼Œé‡æ–°åˆå§‹åŒ–
                agent.messages = list(agent.messages) if agent.messages else []

            # ğŸ”¥ ç«‹å³æ‰§è¡Œæˆªæ–­ï¼Œåˆ©ç”¨å®Œæ•´æ€§ä¿æŠ¤æœºåˆ¶ä¿æŠ¤å·¥å…·è°ƒç”¨é“¾
            if hasattr(agent, "_truncate_context_messages"):
                success = agent._truncate_context_messages(force=True)
                if success:
                    # æˆªæ–­æˆåŠŸåï¼Œæ’å…¥æ‘˜è¦æ¶ˆæ¯
                    summary_msg = Message(role="assistant", content=f"[Summary]\n{summary}")
                    
                    # æ’å…¥åˆ°é€‚å½“ä½ç½®ï¼ˆåœ¨systemæ¶ˆæ¯ä¹‹åï¼Œå…¶ä»–æ¶ˆæ¯ä¹‹å‰ï¼‰
                    if hasattr(agent, "messages") and agent.messages:
                        insert_pos = 1 if agent.messages and getattr(agent.messages[0], "role", "") == "system" else 0
                        agent.messages.insert(insert_pos, summary_msg)
                    
                    if hasattr(agent, "_live_messages") and agent._live_messages:
                        insert_pos = 1 if agent._live_messages and getattr(agent._live_messages[0], "role", "") == "system" else 0
                        agent._live_messages.insert(insert_pos, summary_msg)
                    
                    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                    agent.session_state.setdefault("context_management", {})
                    cm = agent.session_state["context_management"]
                    cm["truncation_count"] = cm.get("truncation_count", 0) + 1
                    cm["last_truncation_time"] = datetime.now().isoformat()
                    
                    return "âœ… å·²ç«‹å³æ‰§è¡Œä¸Šä¸‹æ–‡å‹ç¼©å¹¶æ’å…¥æ‘˜è¦"
                else:
                    return "âš ï¸ æˆªæ–­å¤±è´¥ï¼Œä¸Šä¸‹æ–‡æœªèƒ½æœ‰æ•ˆå‹ç¼©"
            else:
                return "âŒ æˆªæ–­åŠŸèƒ½ä¸å¯ç”¨"

        # å°† summarize_context å·¥å…·åŠ å…¥ agent
        self.tools.append(summarize_context)
    
    def _patch_model_methods(self):
        """ç»™modelæ‰“è¡¥ä¸ï¼Œæ‹¦æˆª_process_model_responseæ–¹æ³•"""
        logger.debug(f"ğŸ”§ ContextManagedAgent: ç»™Modelæ‰“è¡¥ä¸ - {type(self.model).__name__}({self.model.id})")
        logger.debug(f"ğŸ”§ Modelå¯¹è±¡: {self.model}")
        logger.debug(f"ğŸ”§ Modelæœ‰_process_model_response: {hasattr(self.model, '_process_model_response')}")
        logger.debug(f"ğŸ”§ Modelæœ‰_aprocess_model_response: {hasattr(self.model, '_aprocess_model_response')}")
        
        if not hasattr(self.model, '_process_model_response'):
            logger.debug(f"âŒ Modelæ²¡æœ‰_process_model_responseæ–¹æ³•ï¼Œè·³è¿‡è¡¥ä¸")
            return
        if not hasattr(self.model, '_aprocess_model_response'):
            logger.debug(f"âŒ Modelæ²¡æœ‰_aprocess_model_responseæ–¹æ³•ï¼Œè·³è¿‡è¡¥ä¸")
            return
            
        original_process = self.model._process_model_response
        original_aprocess = self.model._aprocess_model_response
        logger.debug(f"ğŸ”§ åŸå§‹æ–¹æ³•è·å–æˆåŠŸ: {original_process}, {original_aprocess}")
        
        logger.debug("ğŸ”§ æ­¥éª¤E: åˆ›å»ºè¡¥ä¸å‡½æ•°")
        def patched_sync(*args, **kwargs):
            # ç®€æ´åŒ…è£…ï¼Œä»…ä¿æŒåŸé€»è¾‘ï¼Œé¿å…é‡å¤tokenç›‘æ§
            logger.debug("ğŸš€ åŒæ­¥è¡¥ä¸è°ƒç”¨")
            return original_process(*args, **kwargs)
        
        async def patched_async(*args, **kwargs):
            logger.debug("ğŸš€ å¼‚æ­¥è¡¥ä¸è°ƒç”¨")
            return await original_aprocess(*args, **kwargs)
        
        # åº”ç”¨è¡¥ä¸
        self.model._process_model_response = patched_sync
        self.model._aprocess_model_response = patched_async
        logger.debug(f"âœ… è¡¥ä¸åº”ç”¨æˆåŠŸ!")
        logger.debug(f"âœ… æ–°çš„_process_model_response: {self.model._process_model_response}")
        logger.debug(f"âœ… æ–°çš„_aprocess_model_response: {self.model._aprocess_model_response}")
    
    def _safe_get_first(self, value, default=0):
        """å®‰å…¨è·å–åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªå€¼æˆ–ç›´æ¥è¿”å›æ•°å€¼"""
        if isinstance(value, list) and len(value) > 0:
            return value[0]
        elif isinstance(value, (int, float)):
            return value
        return default

    def _get_actual_token_usage(self, is_new_run: bool = False) -> Dict[str, Union[int, float]]:
        """è·å–å®é™…tokenä½¿ç”¨æƒ…å†µ
        
        Args:
            is_new_run: æ˜¯å¦æ˜¯æ–°è¿è¡Œå¼€å§‹æ—¶çš„æ£€æŸ¥
        """
        try:
            # ä»run_response.metricsè·å–æ•°æ®
            if hasattr(self, 'run_response') and self.run_response and self.run_response.metrics:
                metrics = self.run_response.metrics
                logger.debug(f"ä»run_response.metricsè·å–æ•°æ®: {metrics}")
                    
                total_tokens = self._safe_get_first(metrics.get('total_tokens', 0))
                usage_percentage = (total_tokens / self.max_context_tokens) * 100 if self.max_context_tokens > 0 else 0.0
                
                return {
                    'total_tokens': total_tokens,
                    'usage_percentage': usage_percentage,
                    'data_source': 'metrics'
                }
                
            # åªåœ¨éæ–°è¿è¡Œæ—¶æ˜¾ç¤ºè­¦å‘Š
            if not is_new_run:
                logger.warning("âš ï¸ æ— æ³•ä»metricsè·å–æœ‰æ•ˆçš„tokenæ•°æ®")
            return {'total_tokens': 0, 'usage_percentage': 0, 'data_source': 'no_metrics_available'}
            
        except Exception as e:
            logger.error(f"âŒ è·å–tokenä½¿ç”¨æ•°æ®å¤±è´¥: {str(e)}")
            return {'total_tokens': 0, 'usage_percentage': 0, 'data_source': 'error'}

    def _calculate_context_usage(self) -> Dict[str, Any]:
        """è®¡ç®—å½“å‰ä¸Šä¸‹æ–‡ä½¿ç”¨æƒ…å†µ - å·²åºŸå¼ƒï¼Œä½¿ç”¨_get_actual_token_usageä»£æ›¿"""
        # ğŸ”¥ åºŸå¼ƒæ–¹æ³•ï¼šç›´æ¥è°ƒç”¨æ­£ç¡®çš„tokenè®¡ç®—æ–¹æ³•
        logger.warning("âš ï¸ _calculate_context_usageå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨_get_actual_token_usage")
        usage_info = self._get_actual_token_usage()
        # è¡¥å……ç¼ºå¤±çš„å­—æ®µä»¥ä¿æŒå…¼å®¹æ€§
        usage_info.update({
            'usage_percentage': (usage_info.get('total_tokens', 0) / self.max_context_tokens) * 100 if self.max_context_tokens > 0 else 0.0,
            'remaining_tokens': max(0, self.max_context_tokens - usage_info.get('total_tokens', 0)),
            'should_warn': False,
            'should_truncate': False
        })
        usage_info['max_tokens'] = self.max_context_tokens
        return usage_info
    
    def _add_context_warning_to_result(self, original_result: str, usage_info: Dict[str, Any]) -> str:
        """åœ¨å·¥å…·ç»“æœä¸­æ·»åŠ ä¸Šä¸‹æ–‡ä½¿ç”¨è­¦å‘Šå’ŒçŠ¶æ€ä¿¡æ¯"""
        context_status = ""
        
        # è·å–æˆªæ–­ç»Ÿè®¡ä¿¡æ¯
        truncation_count = self.session_state.get('context_management', {}).get('truncation_count', 0)
        last_truncation = self.session_state.get('context_management', {}).get('last_truncation_time')
        
        # ğŸ“Š å§‹ç»ˆæ˜¾ç¤ºä¸Šä¸‹æ–‡çŠ¶æ€
        context_status += f"\n\nğŸ“Š **ä¸Šä¸‹æ–‡ç®¡ç†çŠ¶æ€**: {usage_info['total_tokens']}/{self.max_context_tokens} tokens ({usage_info['usage_percentage']:.1f}%)"
        
        if truncation_count > 0:
            context_status += f"\nğŸ”„ **æˆªæ–­å†å²**: å·²æ‰§è¡Œ{truncation_count}æ¬¡æˆªæ–­ï¼Œæœ€è¿‘ä¸€æ¬¡: {last_truncation[:19] if last_truncation else 'N/A'}"
            context_status += f"\nğŸ’¡ **æé†’**: è¯¦ç»†å¯¹è¯å†å²å·²å‹ç¼©ï¼Œå¯ç”¨å·¥å…·æŸ¥è¯¢HCAå†å²è·å–åˆ†æè¿›åº¦"
        
        # âš ï¸ è­¦å‘Šé˜¶æ®µ (70%-80%)
        if usage_info['usage_percentage'] >= (self.warning_threshold * 100):
            warning = f"""
âš ï¸ **ä¸Šä¸‹æ–‡ä½¿ç”¨è­¦å‘Š**: å·²ä½¿ç”¨{usage_info['usage_percentage']:.1f}%
ğŸ”§ **æœºåˆ¶è¯´æ˜**: ä¸‹ä¸€è½®è¿è¡Œå‰å°†è‡ªåŠ¨å‹ç¼©æœ€æ—§çš„å¯¹è¯å†å²ï¼Œå½“å‰HCAçŠ¶æ€ä¸å—å½±å“
ğŸ“š **æ•°æ®ä¿æŠ¤**: session_stateä¸­çš„HCAå†å²ã€å¥–åŠ±ç­‰æ ¸å¿ƒæ•°æ®å®Œå…¨å®‰å…¨
å‰©ä½™å®¹é‡: {usage_info['remaining_tokens']} tokens
"""
            context_status += warning
        
        return f"{original_result}{context_status}"
    
    def _create_truncation_summary(self, truncated_messages: List, count: int) -> Any:
        """åˆ›å»ºè¢«æˆªæ–­æ¶ˆæ¯çš„æ‘˜è¦"""
        # æå–å…³é”®ä¿¡æ¯
        hca_findings = []
        tool_calls = []
        important_discoveries = []
        
        for msg in truncated_messages:
            content = str(msg.content) if msg.content else ""
            
            # æå–HCAç›¸å…³ä¿¡æ¯
            if any(keyword in content.lower() for keyword in ['h-', 'hypothesis', 'å‡è®¾', 'cvss', 'æ¼æ´']):
                hca_findings.append(content[:200] + "..." if len(content) > 200 else content)
            
            # æå–å·¥å…·è°ƒç”¨
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tc in msg.tool_calls:
                    try:
                        # å…¼å®¹å¤šç§å½¢æ€ï¼ˆå¯¹è±¡æˆ– dictï¼‰
                        if isinstance(tc, dict):
                            _fn_data = tc.get("function", {}) if isinstance(tc.get("function"), dict) else {}
                            name = _fn_data.get("name") or tc.get("tool_name") or tc.get("name")
                            args = _fn_data.get("arguments") or tc.get("tool_args") or tc.get("arguments")
                        else:
                            # å¯¹è±¡å½¢å¼
                            fn_obj = getattr(tc, "function", None)
                            name = getattr(fn_obj, "name", None) or getattr(tc, "tool_name", None)
                            args = getattr(fn_obj, "arguments", None) or getattr(tc, "tool_args", None)
                        if name:
                            tool_calls.append(f"{name}({args})" if args else name)
                    except Exception:
                        # å¿½ç•¥è§£æå¤±è´¥çš„æ¡ç›®ï¼Œç¡®ä¿æ‘˜è¦ç”Ÿæˆä¸ä¸­æ–­
                        continue
            
            # æå–é‡è¦å‘ç°
            if any(keyword in content.lower() for keyword in ['å‘ç°', 'found', 'vulnerability', 'exploit']):
                important_discoveries.append(content[:150] + "..." if len(content) > 150 else content)
        
        # æ„å»ºæ‘˜è¦æ¶ˆæ¯
        summary_content = f"""
ğŸ“‹ **ä¸Šä¸‹æ–‡å‹ç¼©æ‘˜è¦** (æˆªæ–­äº†{count}æ¡æ¶ˆæ¯)
æˆªæ–­æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ” **HCAç›¸å…³å‘ç°** ({len(hca_findings)}æ¡):
{chr(10).join(f"- {finding}" for finding in hca_findings[:5])}
{'...(æ›´å¤šå†…å®¹å·²æˆªæ–­)' if len(hca_findings) > 5 else ''}

ğŸ› ï¸ **å·¥å…·è°ƒç”¨è®°å½•** ({len(tool_calls)}æ¬¡):
{chr(10).join(f"- {call}" for call in tool_calls[:10])}
{'...(æ›´å¤šè°ƒç”¨å·²æˆªæ–­)' if len(tool_calls) > 10 else ''}

ğŸ’¡ **é‡è¦å‘ç°** ({len(important_discoveries)}æ¡):
{chr(10).join(f"- {discovery}" for discovery in important_discoveries[:3])}
{'...(æ›´å¤šå‘ç°å·²æˆªæ–­)' if len(important_discoveries) > 3 else ''}

âš ï¸ **æ³¨æ„**: è¯¦ç»†çš„HCAå†å²å¯é€šè¿‡ query_hca_history() å·¥å…·æŸ¥è¯¢
"""
        
        # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯å¯¹è±¡ (ä½¿ç”¨æ ‡å‡†Messageç±»)
        from agno.models.message import Message
        return Message(role="system", content=summary_content)
    
    def record_hca_to_history(self, hca_data: Dict[str, Any]):
        """è®°å½•HCAæ•°æ®åˆ°å®Œæ•´å†å²ä¸­"""
        self._ensure_hca_history_structure()
        
        hca_record = {
            'id': hca_data.get('id', f"HCA-{len(self.session_state['hca_complete_history']) + 1:03d}"),
            'timestamp': datetime.now().isoformat(),
            'hypothesis': hca_data.get('hypothesis', ''),
            'challenge': hca_data.get('challenge', ''),
            'adaptation': hca_data.get('adaptation', ''),
            'status': hca_data.get('status', 'pending'),
            'evidence': hca_data.get('evidence', ''),
            'cvss_score': hca_data.get('cvss_score', None),
            'files_analyzed': hca_data.get('files_analyzed', []),
            'tools_used': hca_data.get('tools_used', [])
        }
        
        self.session_state['hca_complete_history'].append(hca_record)
        logger.info(f"ğŸ“š **HCAè®°å½•å·²ä¿å­˜**: {hca_record['id']}")
    

    
    async def arun(self, *args, **kwargs):
        """é‡å†™å¼‚æ­¥arunæ–¹æ³•ï¼Œåœ¨è¿è¡Œç»“æŸåè¿›è¡Œä¸Šä¸‹æ–‡ç®¡ç†"""
        if not hasattr(self, 'session_state'):
            self.session_state = {}
        if 'context_management' not in self.session_state:
            self.session_state['context_management'] = {}
        try:
            current_usage = self._get_actual_token_usage(is_new_run=True)
            if current_usage['total_tokens'] >= (self.max_context_tokens * self.truncate_threshold):
                logger.info(f"ğŸ”„ ä¸Šä¸€æ¬¡è¿è¡Œtokenä½¿ç”¨ç‡è¾¾åˆ°{current_usage['usage_percentage']:.1f}%ï¼Œæ‰§è¡Œæˆªæ–­")
                self._truncate_context_messages()
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå‰æ£€æŸ¥å¤±è´¥: {str(e)}")
        response = await super().arun(*args, **kwargs)
        try:
            current_usage = self._get_actual_token_usage()
            self.session_state['context_management']['last_run_token_usage'] = current_usage['total_tokens']
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œåæ›´æ–°å¤±è´¥: {str(e)}")
        return response

    def run(self, message: str = None, **kwargs) -> RunResponse:
        """é‡å†™runæ–¹æ³•ï¼Œåœ¨è¿è¡Œç»“æŸåè¿›è¡Œä¸Šä¸‹æ–‡ç®¡ç†"""
        if not hasattr(self, 'session_state'):
            self.session_state = {}
        if 'context_management' not in self.session_state:
            self.session_state['context_management'] = {}
        try:
            current_usage = self._get_actual_token_usage(is_new_run=True)
            if current_usage['total_tokens'] >= (self.max_context_tokens * self.truncate_threshold):
                logger.info(f"ğŸ”„ ä¸Šä¸€æ¬¡è¿è¡Œtokenä½¿ç”¨ç‡è¾¾åˆ°{current_usage['usage_percentage']:.1f}%ï¼Œæ‰§è¡Œæˆªæ–­")
                self._truncate_context_messages()
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå‰æ£€æŸ¥å¤±è´¥: {str(e)}")
        response = super().run(message, **kwargs)
        try:
            current_usage = self._get_actual_token_usage()
            self.session_state['context_management']['last_run_token_usage'] = current_usage['total_tokens']
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œåæ›´æ–°å¤±è´¥: {str(e)}")
        return response

    def _handle_post_response(self, run_response: RunResponse):
        """åœ¨æ¯ä¸ª run_response ä¹‹åæ‰§è¡Œçš„é€»è¾‘ï¼ˆæˆªæ–­ç­‰ï¼‰"""
        if not run_response:
            return
            
        if not run_response.metrics:
            return
            
        try:
            # ä»RunResponse.metricsè·å–tokenä½¿ç”¨æƒ…å†µ
            # ä½¿ç”¨ç±»çš„_safe_get_firstæ–¹æ³•
            
            if isinstance(run_response.metrics, dict):
                # ç›´æ¥å¤„ç†å­—å…¸
                metrics_dict = run_response.metrics
                total_tokens_raw = metrics_dict.get('total_tokens', 0)
                total_tokens = self._safe_get_first(total_tokens_raw)
                
                if total_tokens == 0:
                    input_tokens = self._safe_get_first(metrics_dict.get('input_tokens', 0))
                    output_tokens = self._safe_get_first(metrics_dict.get('output_tokens', 0))
                    total_tokens = input_tokens + output_tokens
            elif hasattr(run_response.metrics, '__dict__'):
                # å¤„ç†å¯¹è±¡
                metrics_dict = run_response.metrics.__dict__
                total_tokens_raw = metrics_dict.get('total_tokens', 0)
                total_tokens = self._safe_get_first(total_tokens_raw)
            else:
                total_tokens = getattr(run_response.metrics, 'total_tokens', 0)
            
            usage_percentage = (total_tokens / self.max_context_tokens) * 100 if self.max_context_tokens > 0 else 0.0
            
            logger.info(f"ğŸ“Š ContextManagedAgent Tokenä½¿ç”¨: {total_tokens}/{self.max_context_tokens} ({usage_percentage:.1f}%)")
            
            # æ›´æ–°sessionçŠ¶æ€
            if not hasattr(self, 'session_state'):
                self.session_state = {}
            if 'context_management' not in self.session_state:
                self.session_state['context_management'] = {}
            self.session_state['context_management']['last_run_token_usage'] = total_tokens
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡è®°éœ€è¦æˆªæ–­çš„æƒ…å†µ
            needs_truncation = self.session_state['context_management'].get('needs_truncation', False)
            if needs_truncation:
                reason = self.session_state['context_management'].get('truncation_reason', 'æœªçŸ¥åŸå› ')
                logger.warning(f"ğŸ”„ ContextManagedAgent æ‰§è¡Œå»¶è¿Ÿæˆªæ–­: {reason}")
                
                # æ‰§è¡Œæˆªæ–­
                success = self._truncate_context_messages()
                if success:
                    logger.info(f"âœ… æˆªæ–­æ‰§è¡ŒæˆåŠŸ")
                else:
                    logger.error(f"âŒ æˆªæ–­æ‰§è¡Œå¤±è´¥")
                
                # æ¸…é™¤æˆªæ–­æ ‡è®°
                self.session_state['context_management']['needs_truncation'] = False
                self.session_state['context_management'].pop('truncation_reason', None)
            
            # å»¶è¿Ÿæˆªæ–­é€»è¾‘å·²åˆ é™¤ï¼Œç°åœ¨æ‰€æœ‰æˆªæ–­éƒ½æ˜¯ç«‹å³æ‰§è¡Œ
            
            # --- åŒæ­¥ _live_messages â†â†’ run_response.messages & current_run ---
            try:
                # 1) ç¡®ä¿ _live_messages åŒ…å«æœ¬è½®æœ€æ–°å…¨éƒ¨æ¶ˆæ¯ï¼ˆå« tool-msgï¼‰
                if run_response.messages:
                    self._live_messages = list(run_response.messages)
                # 2) ä¿è¯ current_run.messages ä¸ _live_messages ä¿æŒä¸€è‡´
                if (
                    hasattr(self.memory, "current_run")
                    and getattr(self.memory.current_run, "messages", None) is not None
                ):
                    self.memory.current_run.messages = list(self._live_messages)  # type: ignore
                # 3) å°† _live_messages å†™å› run_responseï¼Œä¾›ä¸Šå±‚æ—¥å¿—æˆ–é“¾è·¯ä½¿ç”¨
                run_response.messages = list(self._live_messages)
            except Exception:
                pass
            
        except Exception as e:
            logger.error(f"âŒ Tokenç›‘æ§å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

    def _run(
        self,
        message: Optional[Union[str, List, Dict, Message]] = None,
        *,
        stream: bool = False,
        session_id: str,
        user_id: Optional[str] = None,
        audio: Optional[Sequence[Audio]] = None,
        images: Optional[Sequence[Image]] = None,
        videos: Optional[Sequence[Video]] = None,
        files: Optional[Sequence[File]] = None,
        messages: Optional[Sequence[Union[Dict, Message]]] = None,
        knowledge_filters: Optional[Dict[str, Any]] = None,
        stream_intermediate_steps: bool = False,
        run_response: RunResponse,
        **kwargs: Any,
    ) -> Iterator[RunResponse]:
        """é‡å†™_runæ–¹æ³•ï¼Œåœ¨model.response()åæ’å…¥æˆªæ–­é€»è¾‘"""
        logger.debug("ğŸ¯ ContextManagedAgent._run å¼€å§‹æ‰§è¡Œ")

        # --- è°ƒè¯•: æ‰“å°å³å°†å‘é€ç»™æ¨¡å‹çš„å®Œæ•´æ¶ˆæ¯ç»Ÿè®¡ ---
        try:
            all_msgs = self.get_run_messages(
                message=message,
                session_id=session_id,
                user_id=user_id,
                messages=messages,
                audio=audio,
                images=images,
                videos=videos,
                files=files,
            )
            tool_cnt = sum(1 for m in all_msgs if getattr(m, "role", "") == "tool")
            tool_chars = sum(len(str(m.content)) for m in all_msgs if getattr(m, "role", "") == "tool")
            current_cnt = len(self.memory.current_run.messages) if getattr(self.memory, "current_run", None) else 0
            prefix_cnt = len(all_msgs) - current_cnt
            logger.debug(
                f"[PROMPT-DEBUG] total_msgs={len(all_msgs)}, prefix_msgs={prefix_cnt}, "
                f"current_run_msgs={current_cnt}, tool_msgs={tool_cnt}, tool_chars={tool_chars}"
            )
        except Exception as _pd_err:
            logger.debug(f"PROMPT-DEBUG error: {_pd_err}")

        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–ç”Ÿæˆå™¨
        for response in super()._run(
            message=message,
            stream=stream,
            session_id=session_id,
            user_id=user_id,
            audio=audio,
            images=images,
            videos=videos,
            files=files,
            messages=messages,
            knowledge_filters=knowledge_filters,
            stream_intermediate_steps=stream_intermediate_steps,
            run_response=run_response,
            **kwargs
        ):
            # åœ¨æ¯ä¸ªresponseåæ£€æŸ¥æ˜¯å¦éœ€è¦æˆªæ–­
            self._handle_post_response(response)
            yield response

    async def _arun(
        self,
        message: Optional[Union[str, List, Dict, Message]] = None,
        *,
        stream: bool = False,
        session_id: str,
        user_id: Optional[str] = None,
        audio: Optional[Sequence[Audio]] = None,
        images: Optional[Sequence[Image]] = None,
        videos: Optional[Sequence[Video]] = None,
        files: Optional[Sequence[File]] = None,
        messages: Optional[Sequence[Union[Dict, Message]]] = None,
        stream_intermediate_steps: bool = False,
        knowledge_filters: Optional[Dict[str, Any]] = None,
        run_response: RunResponse,
        **kwargs: Any,
    ) -> AsyncIterator[RunResponse]:
        """é‡å†™å¼‚æ­¥_arunï¼Œåœ¨è°ƒç”¨çˆ¶ç±»å‰æ‰“å°ä¸Šä¸‹æ–‡ç»Ÿè®¡"""
        logger.debug("ğŸ¯ ContextManagedAgent._arun å¼€å§‹æ‰§è¡Œ")

        # --- è°ƒè¯•: æ‰“å°å³å°†å‘é€ç»™æ¨¡å‹çš„å®Œæ•´æ¶ˆæ¯ç»Ÿè®¡ ---
        try:
            all_msgs = self.get_run_messages(
                message=message,
                session_id=session_id,
                user_id=user_id,
                messages=messages,
                audio=audio,
                images=images,
                videos=videos,
                files=files,
            )
            tool_cnt = sum(1 for m in all_msgs if getattr(m, "role", "") == "tool")
            tool_chars = sum(len(str(m.content)) for m in all_msgs if getattr(m, "role", "") == "tool")
            current_cnt = len(self.memory.current_run.messages) if getattr(self.memory, "current_run", None) else 0
            prefix_cnt = len(all_msgs) - current_cnt
            logger.debug(
                f"[PROMPT-DEBUG] total_msgs={len(all_msgs)}, prefix_msgs={prefix_cnt}, "
                f"current_run_msgs={current_cnt}, tool_msgs={tool_cnt}, tool_chars={tool_chars}"
            )
        except Exception as _pd_err:
            logger.debug(f"PROMPT-DEBUG error: {_pd_err}")
        # è°ƒç”¨çˆ¶ç±»å¼‚æ­¥æ–¹æ³•
        async for response in super()._arun(
            message=message,
            stream=stream,
            session_id=session_id,
            user_id=user_id,
            audio=audio,
            images=images,
            videos=videos,
            files=files,
            messages=messages,
            stream_intermediate_steps=stream_intermediate_steps,
            knowledge_filters=knowledge_filters,
            run_response=run_response,
            **kwargs
        ):
            self._handle_post_response(response)
            yield response

    def _perform_context_management_check(self):
        """æ‰§è¡Œä¸Šä¸‹æ–‡ç®¡ç†æ£€æŸ¥"""
        logger.debug("ğŸ” æ‰§è¡Œä¸Šä¸‹æ–‡ç®¡ç†æ£€æŸ¥...")
        
        usage_data = self._calculate_context_usage()
        
        # è®°å½•å½“å‰çŠ¶æ€
        data_source = usage_data.get('data_source', 'unknown')
        logger.debug(f"CONTEXT_DEBUG: å½“å‰ä¸Šä¸‹æ–‡: {usage_data['total_tokens']}/{self.max_context_tokens} tokens ({usage_data['usage_percentage']:.1f}%) - æ•°æ®æº: {data_source}")
        
        # æ£€æŸ¥è­¦å‘Š
        if usage_data['should_warn'] and not self._warning_sent:
            logger.warning(f"âš ï¸ ä¸Šä¸‹æ–‡ä½¿ç”¨ç‡è¿‡é«˜: {usage_data['usage_percentage']:.1f}% (é˜ˆå€¼: {self.warning_threshold*100:.1f}%)")
            logger.warning(f"   å½“å‰Tokenæ•°: {usage_data['total_tokens']}/{self.max_context_tokens}")
            logger.warning(f"   å‰©ä½™Token: {usage_data['remaining_tokens']}")
            logger.warning(f"   æ•°æ®æº: {data_source}")
            self._warning_sent = True
        
        # æ£€æŸ¥æˆªæ–­
        if usage_data['should_truncate']:
            logger.warning(f"ğŸ”¥ ä¸Šä¸‹æ–‡å³å°†è¶…é™: {usage_data['usage_percentage']:.1f}% (é˜ˆå€¼: {self.truncate_threshold*100:.1f}%)")
            logger.warning(f"   å½“å‰Tokenæ•°: {usage_data['total_tokens']}/{self.max_context_tokens}")
            logger.warning(f"   å¼€å§‹æ‰§è¡Œæˆªæ–­...")
            truncated = self._truncate_context_messages()
            if truncated:
                logger.info(f"âœ… ä¸Šä¸‹æ–‡æˆªæ–­å®Œæˆ")
            else:
                logger.warning(f"âš ï¸ æˆªæ–­å¤±è´¥æˆ–æ— éœ€æˆªæ–­")
        
        return usage_data
    
    def _log_pre_run_status(self, args, kwargs):
        """è®°å½•è¿è¡Œå‰çŠ¶æ€ï¼ˆä¸»è¦ç”¨äºæ—¥å¿—ï¼‰"""
        session_id = kwargs.get('session_id', 'unknown')
        logger.debug(f"ğŸš€ **[æ‰§è¡Œå‰æ£€æŸ¥] session_id: {session_id}**")
        
        # æ‰§è¡Œå‰æ£€æŸ¥ï¼ˆæ­¤æ—¶å¯èƒ½æ²¡æœ‰æœ€æ–°çš„run_responseï¼‰
        usage_data = self._calculate_context_usage()
        logger.debug(f"   è¿è¡Œå‰TokençŠ¶æ€: {usage_data['total_tokens']}/{self.max_context_tokens} ({usage_data['usage_percentage']:.1f}%)")
        logger.debug(f"   æ•°æ®æº: {usage_data.get('data_source', 'unknown')}")
        
        return usage_data

    def _perform_post_run_context_management(self):
        """æ‰§è¡Œåè¿›è¡Œä¸Šä¸‹æ–‡ç®¡ç†ï¼ˆæ­¤æ—¶æœ‰æœ€æ–°çš„run_responseæ•°æ®ï¼‰"""
        logger.debug("ğŸ“‹ **[æ‰§è¡Œåæ£€æŸ¥] å¼€å§‹ä¸Šä¸‹æ–‡ç®¡ç†**")
        
        # è·å–æœ€æ–°çš„tokenä½¿ç”¨æƒ…å†µï¼ˆæ­¤æ—¶åº”è¯¥æœ‰run_responseæ•°æ®ï¼‰
        usage_data = self._calculate_context_usage()
        
        data_source = usage_data.get('data_source', 'unknown')
        logger.debug(f"   æ‰§è¡ŒåTokençŠ¶æ€: {usage_data['total_tokens']}/{self.max_context_tokens} ({usage_data['usage_percentage']:.1f}%)")
        logger.debug(f"   æ•°æ®æº: {data_source}")
        
        # å¦‚æœä½¿ç”¨çš„æ˜¯çœŸå®tokenæ•°æ®ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if data_source == 'run_response_metrics':
            logger.debug(f"   âœ… çœŸå®Tokenè¯¦æƒ…:")
            logger.debug(f"      è¾“å…¥Token: {usage_data.get('input_tokens', 0)}")
            logger.debug(f"      è¾“å‡ºToken: {usage_data.get('output_tokens', 0)}")
            logger.debug(f"      ç¼“å­˜Token: {usage_data.get('cached_tokens', 0)}")
            logger.debug(f"      æ¨ç†Token: {usage_data.get('reasoning_tokens', 0)}")
        
        # æ‰§è¡Œä¸Šä¸‹æ–‡ç®¡ç†æ£€æŸ¥
        self._perform_context_management_check()
        
        return usage_data
    
    def _estimate_tokens_for_message(self, message: str) -> int:
        """ä¼°ç®—æ¶ˆæ¯çš„tokenæ•°é‡"""
        logger.debug(f"ğŸ’¬ **[Tokenä¼°ç®—] ä¼°ç®—æ¶ˆæ¯Tokenæ•°**")
        
        if not message:
            logger.debug(f"   æ¶ˆæ¯ä¸ºç©ºï¼Œè¿”å›0")
            return 0
        
        # ç®€å•çš„tokenä¼°ç®—ï¼šå­—ç¬¦æ•° Ã— 0.35 (åŸºäºä¸€èˆ¬çš„ä¸­è‹±æ–‡æ··åˆæ¯”ä¾‹)
        char_count = len(str(message))
        estimated_tokens = int(char_count * 0.35)
        
        logger.debug(f"   æ¶ˆæ¯é•¿åº¦: {char_count} å­—ç¬¦")
        logger.debug(f"   ä¼°ç®—Token: {char_count} Ã— 0.35 = {estimated_tokens}")
        
        return estimated_tokens
    
    def print_response(
        self, 
        message: Optional[str] = None,
        **kwargs,
    ) -> RunResponse:
        """é‡å†™print_responseæ–¹æ³•ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ç®¡ç†"""
        logger.info("\nğŸ–¨ï¸ **[å“åº”è¾“å‡º] print_response å¼€å§‹**")
        
        # æ‰§è¡Œå‰ä¸Šä¸‹æ–‡æ£€æŸ¥
        usage_info = self._calculate_context_usage()
        logger.debug(f"   è¾“å‡ºå‰ä¸Šä¸‹æ–‡: {usage_info['total_tokens']}/{usage_info['max_tokens']} ({usage_info['usage_percentage']:.1f}%)")
        
        # è°ƒç”¨åŸå§‹æ–¹æ³•ï¼ˆä»…ä¼ é€’å…³é”®å­—å‚æ•°ï¼Œé¿å…ä½ç½®å‚æ•°æ•°é‡ä¸åŒ¹é…ï¼‰
        logger.debug(f"   ğŸš€ è°ƒç”¨ super().print_response()...")
        result = super().print_response(message, **kwargs)
        logger.debug(f"   âœ… super().print_response() å®Œæˆ")
        
        # æ‰§è¡Œåå†æ¬¡æ£€æŸ¥å¹¶æ·»åŠ è­¦å‘Š
        final_usage = self._calculate_context_usage()
        logger.debug(f"   è¾“å‡ºåä¸Šä¸‹æ–‡: {final_usage['total_tokens']}/{final_usage['max_tokens']} ({final_usage['usage_percentage']:.1f}%)")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ è­¦å‘Šä¿¡æ¯åˆ°å“åº”
        if result and hasattr(result, 'content') and result.content:
            logger.debug(f"   ğŸ“ æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ ä¸Šä¸‹æ–‡è­¦å‘Š...")
            enhanced_content = self._add_context_warning_to_result(result.content, final_usage)
            if enhanced_content != result.content:
                logger.debug(f"   âœ… å·²æ·»åŠ ä¸Šä¸‹æ–‡çŠ¶æ€ä¿¡æ¯åˆ°å“åº”")
                result.content = enhanced_content
            else:
                logger.debug(f"   â„¹ï¸ æ— éœ€æ·»åŠ é¢å¤–çŠ¶æ€ä¿¡æ¯")
        
        logger.info(f"ğŸ–¨ï¸ **[å“åº”è¾“å‡º] print_response ç»“æŸ**\n")
        return result
    
    def get_context_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡çŠ¶æ€ä¿¡æ¯"""
        usage_info = self._calculate_context_usage()
        
        return {
            'usage_info': usage_info,
            'hca_history_count': len(self.session_state.get('hca_complete_history', [])),
            'truncation_count': self.session_state.get('context_management', {}).get('truncation_count', 0),
            'last_truncation': self.session_state.get('context_management', {}).get('last_truncation_time'),
            'message_count': len(self.messages) if hasattr(self, 'messages') and self.messages else 0
        }

    def _handle_message_post_log(self, assistant_message: Optional[Message]):
        """åœ¨assistant_message.log(metrics=True)åç«‹å³è°ƒç”¨çš„tokenç›‘æ§é€»è¾‘"""
        logger.debug(f"ğŸ” >>> _handle_message_post_log è¢«è°ƒç”¨! assistant_message={type(assistant_message)}")
        logger.debug(f"ğŸ” >>> assistant_message.role={getattr(assistant_message, 'role', 'None')}")
        logger.debug(f"ğŸ” >>> assistant_message.contenté¢„è§ˆ={getattr(assistant_message, 'content', 'None')[:100] if getattr(assistant_message, 'content', None) else 'None'}")
        
        if not assistant_message:
            logger.debug(f"ğŸ” >>> assistant_message ä¸º Noneï¼Œè¿”å›")
            return
            
        if not hasattr(assistant_message, 'metrics') or not assistant_message.metrics:
            logger.debug(f"ğŸ” >>> assistant_message.metrics ä¸º Noneï¼Œè¿”å›ã€‚hasattr(assistant_message, 'metrics')={hasattr(assistant_message, 'metrics')}")
            return
            
        logger.debug(f"ğŸ” >>> assistant_message.metrics å­˜åœ¨: {type(assistant_message.metrics)}")
        logger.debug(f"ğŸ” >>> metrics.total_tokens={getattr(assistant_message.metrics, 'total_tokens', 'None')}")
        logger.debug(f"ğŸ” >>> metrics.input_tokens={getattr(assistant_message.metrics, 'input_tokens', 'None')}")
        logger.debug(f"ğŸ” >>> metrics.output_tokens={getattr(assistant_message.metrics, 'output_tokens', 'None')}")
        
        # ç¡®ä¿session_stateå­˜åœ¨
        if not hasattr(self, 'session_state'):
            self.session_state = {}
        if 'context_management' not in self.session_state:
            self.session_state['context_management'] = {}
            
        try:
            # ä»assistant_message.metricsè·å–tokenä½¿ç”¨æƒ…å†µ
            metrics = assistant_message.metrics
            
            # è·å–å½“å‰æ¶ˆæ¯çš„tokenæ•°æ®
            total_tokens = getattr(metrics, 'total_tokens', 0)
            input_tokens = getattr(metrics, 'input_tokens', 0)
            output_tokens = getattr(metrics, 'output_tokens', 0)
            cached_tokens = getattr(metrics, 'cached_tokens', 0)
            reasoning_tokens = getattr(metrics, 'reasoning_tokens', 0)
            
            usage_percentage = (total_tokens / self.max_context_tokens) * 100 if self.max_context_tokens > 0 else 0.0
            
            # æ™ºèƒ½è¾“å‡ºç­–ç•¥ï¼šåªåœ¨éœ€è¦å…³æ³¨æ—¶è¾“å‡º
            should_output = False
            output_level = "info"
            
            # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰è°ƒç”¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            debug_mode = getattr(self, 'debug_mode', False)
            
            if usage_percentage >= (self.truncate_threshold * 100):
                # è¾¾åˆ°æˆªæ–­é˜ˆå€¼ï¼šå…³é”®è¾“å‡º
                should_output = True
                output_level = "critical"
            elif usage_percentage >= (self.warning_threshold * 100):
                # è¾¾åˆ°è­¦å‘Šé˜ˆå€¼ï¼šè­¦å‘Šè¾“å‡º
                should_output = True
                output_level = "warning"
            elif usage_percentage >= 30:  # é™ä½é˜ˆå€¼ä»50%åˆ°30%
                # è¶…è¿‡30%ï¼šç®€å•æé†’
                should_output = True
                output_level = "notice"
            elif debug_mode:
                # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰è°ƒç”¨
                should_output = True
                output_level = "debug"
            # å¦åˆ™é™é»˜ï¼ˆä¸è¾“å‡ºï¼‰
            
            if should_output:
                # æ ¹æ®çº§åˆ«é€‰æ‹©è¾“å‡ºæ ¼å¼
                if output_level == "critical":
                    logger.error(f"ğŸš¨ ContextManagedAgent å…³é”®è­¦å‘Š: Tokenä½¿ç”¨ {total_tokens}/{self.max_context_tokens} ({usage_percentage:.1f}%) - å³å°†æˆªæ–­!")
                elif output_level == "warning":
                    logger.warning(f"âš ï¸ ContextManagedAgent è­¦å‘Š: Tokenä½¿ç”¨ {total_tokens}/{self.max_context_tokens} ({usage_percentage:.1f}%) - æ¥è¿‘ä¸Šé™")
                elif output_level == "notice":
                    logger.info(f"ğŸ“Š ContextManagedAgent æé†’: Tokenä½¿ç”¨ {total_tokens}/{self.max_context_tokens} ({usage_percentage:.1f}%)")
                elif output_level == "debug":
                    logger.debug(f"ğŸ” ContextManagedAgent è°ƒè¯•: Tokenä½¿ç”¨ {total_tokens}/{self.max_context_tokens} ({usage_percentage:.1f}%)")
                
                # è¯¦ç»†ä¿¡æ¯ï¼ˆåªåœ¨è­¦å‘Šçº§åˆ«ä»¥ä¸Šæ˜¾ç¤ºï¼‰
                if output_level in ["warning", "critical"] and (input_tokens > 0 or output_tokens > 0):
                    details = f"è¾“å…¥:{input_tokens}, è¾“å‡º:{output_tokens}"
                    if cached_tokens > 0:
                        details += f", ç¼“å­˜:{cached_tokens}"
                    if reasoning_tokens > 0:
                        details += f", æ¨ç†:{reasoning_tokens}"
                    logger.debug(f"   è¯¦æƒ…: {details}")
            
            # æ›´æ–°sessionçŠ¶æ€
            self.session_state['context_management']['last_run_token_usage'] = total_tokens
            
            # --- å°†æ¶ˆæ¯å†™å…¥å®æ—¶ç¼“å†² ---
            try:
                if assistant_message not in getattr(self, "_live_messages", []):
                    self._live_messages.append(assistant_message)
            except Exception:
                pass
            
            # --- ğŸ”¥ æ–°å¢ï¼šæˆªæ–­ run_messages ä¸­çš„å·¥å…·æ¶ˆæ¯ ---
            self._truncate_tool_messages_in_run_messages()
            

            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦æˆªæ–­ - ä½†ä¸åœ¨è¿™é‡Œæ‰§è¡Œï¼Œè€Œæ˜¯æ ‡è®°éœ€è¦æˆªæ–­
            if total_tokens >= (self.max_context_tokens * self.truncate_threshold):
                logger.warning(f"ğŸ”„ ContextManagedAgent æˆªæ–­æµç¨‹è§¦å‘: tokenä½¿ç”¨ç‡{usage_percentage:.1f}% >= é˜ˆå€¼")

                # 1ï¸âƒ£ å…ˆå°è¯•å‹ç¼©æ—§çš„ tool æ¶ˆæ¯
                compressed = self._compress_old_tool_messages()
                if compressed:
                    logger.info("ğŸ’¡ å·²å‹ç¼©æ—§ tool æ¶ˆæ¯ï¼Œé‡æ–°è®¡ç®—tokenâ€¦")
                    usage_info = self._calculate_context_usage()
                    total_tokens = usage_info.get('total_tokens', total_tokens)
                    usage_percentage = usage_info.get('usage_percentage', usage_percentage)

                # âš ï¸ [å·²ç¦ç”¨] åˆ é™¤æ—§ tool æ¶ˆæ¯ä¼šç ´åå·¥å…·è°ƒç”¨é“¾å®Œæ•´æ€§ï¼Œæ•…ç›´æ¥è·³è¿‡æ­¤æ­¥éª¤
                # if total_tokens >= (self.max_context_tokens * self.truncate_threshold):
                #     dropped = self._drop_old_tool_messages()
                #     if dropped:
                #         logger.info("ğŸ—‘ï¸ å·²åˆ é™¤æ—§ tool æ¶ˆæ¯ï¼Œé‡æ–°è®¡ç®—tokenâ€¦")
                #         usage_info = self._calculate_context_usage()
                #         total_tokens = usage_info.get('total_tokens', total_tokens)
                #         usage_percentage = usage_info.get('usage_percentage', usage_percentage)

                # 3ï¸âƒ£ ğŸ”¥ æ–°é€»è¾‘ï¼šAIå“åº”åç«‹å³æ‰§è¡Œæ€»ç»“ï¼Œä¸ç®¡tool_callsçŠ¶æ€
                if total_tokens >= (self.max_context_tokens * self.truncate_threshold):
                    if self.use_legacy_summary:
                        logger.warning(f"âš ï¸ AIå“åº”åtokenè¶…é™({usage_percentage:.1f}%)ï¼Œç«‹å³æ‰§è¡Œ[æ—§]AIæ€»ç»“æµç¨‹")
                        try:
                            summarized = self._ai_summarize_history_with_context_protection()
                            if summarized:
                                logger.info("ğŸ¤– æ—§AIæ€»ç»“å®Œæˆï¼Œé‡æ–°è®¡ç®—tokenä½¿ç”¨")
                                usage_info = self._calculate_context_usage()
                                total_tokens = usage_info.get('total_tokens', total_tokens)
                                usage_percentage = usage_info.get('usage_percentage', usage_percentage)
                            else:
                                logger.warning("âš ï¸ æ—§AIæ€»ç»“å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæˆªæ–­")
                        except Exception as e:
                            logger.error(f"âŒ æ—§AIæ€»ç»“æ‰§è¡Œå¤±è´¥: {e}ï¼Œç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæˆªæ–­")
                    else:
                        logger.info("ğŸ›‘ å·²ç¦ç”¨æ—§AIæ€»ç»“é€»è¾‘ï¼Œæ”¹ç”± summarize_context å·¥å…·å¤„ç†ã€‚")
            
                    # 4ï¸âƒ£ å…œåº•æˆªæ–­ â€”â€” ä»…åœ¨å¯ç”¨ legacy_summary æ—¶ä¿ç•™
                    if self.use_legacy_summary and total_tokens >= (self.max_context_tokens * self.truncate_threshold):
                        logger.warning("âš ï¸ AIæ€»ç»“åä»è¶…é™ï¼Œæ‰§è¡Œå¯¹è¯æ¡æ•°æˆªæ–­ (legacy mode)")
                        success = self._truncate_context_messages()
                        if success:
                            logger.info("âœ‚ï¸ å·²å³æ—¶æˆªæ–­ä¸Šä¸‹æ–‡ (legacy mode)")
                        else:
                            logger.error("âŒ å³æ—¶æˆªæ–­å¤±è´¥ (legacy mode)")
                            # æ ‡è®°éœ€è¦æˆªæ–­ï¼Œåœ¨Agentå±‚é¢æ‰§è¡Œ
                            self.session_state['context_management']['needs_truncation'] = True
                            self.session_state['context_management']['truncation_reason'] = f"tokenä½¿ç”¨ç‡è¾¾åˆ°{usage_percentage:.1f}%"
                
        except Exception as e:
            logger.error(f"âŒ Tokenç›‘æ§å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

    def _patch_message_log(self):
        """ä¸º agno.models.message.Message.log æ‰“è¡¥ä¸ï¼Œå®ç°å…¨å±€ token ç›‘æ§å›è°ƒ"""
        import logging
        from agno.models.message import Message as _AgnoMessage

        logger = logging.getLogger(__name__)

        # å¦‚æœé¦–æ¬¡æ‰“è¡¥ä¸ï¼Œåˆ™åŒ…è£…åŸå§‹ log æ–¹æ³•
        if not getattr(_AgnoMessage, "_token_monitor_patched", False):
            original_log = _AgnoMessage.log

            def patched_log(msg_self, *args, **kwargs):  # type: ignore
                """åŒ…è£…åçš„å…¨å±€ log æ–¹æ³•"""
                # å…ˆæ‰§è¡ŒåŸå§‹è¡Œä¸ºï¼Œä¿æŒç°æœ‰è¾“å‡ºä¸å˜
                result = original_log(msg_self, *args, **kwargs)

                try:
                    # åœ¨ assistant æˆ– tool æ¶ˆæ¯ä¸”å¸¦ token metrics æ—¶è§¦å‘
                    if (
                        msg_self.role in {"assistant", "tool"}
                        and getattr(msg_self, "metrics", None) is not None
                        and getattr(msg_self.metrics, "total_tokens", 0) > 0
                    ):
                        # è°ƒç”¨å·²æ³¨å†Œçš„æ‰€æœ‰ç›‘æ§å›è°ƒ
                        for hook in getattr(_AgnoMessage, "_token_monitor_hooks", []):
                            try:
                                hook(msg_self)
                            except Exception as hook_err:  # pragma: no cover
                                logger.debug(f"âš ï¸ token ç›‘æ§ hook æ‰§è¡Œå¤±è´¥: {hook_err}")
                except Exception as e:  # pragma: no cover
                    logger.debug(f"âš ï¸ patched_log å†…éƒ¨é”™è¯¯: {e}")

                return result

            # è®¾ç½®è¡¥ä¸åŠæ ‡è®°
            _AgnoMessage.log = patched_log  # type: ignore
            _AgnoMessage._token_monitor_patched = True  # type: ignore
            _AgnoMessage._token_monitor_hooks = []  # type: ignore
            logger.critical("ğŸ¯ Message.log è¡¥ä¸åº”ç”¨æˆåŠŸ!")

                    # æ¯ä¸ª Agent å®ä¾‹æ³¨å†Œè‡ªå·±çš„å›è°ƒï¼Œä½¿å¾—å¤šä¸ª Agent å¯ä»¥å…±å­˜
        def _agent_hook(message):  # type: ignore
            try:
                # é¿å…åŒä¸€æ¡æ¶ˆæ¯è¢«å¤šä¸ª Agent é‡å¤å¤„ç†
                if getattr(message, "_token_monitor_handled", False):
                    return
                # è®¾ç½®æ ‡è®°ï¼Œè¡¨ç¤ºå·²å¤„ç†
                setattr(message, "_token_monitor_handled", True)
                self._handle_message_post_log(message)
                
                # å·¥å…·æ¶ˆæ¯å¤„ç†å®Œæˆï¼Œæ— éœ€é¢å¤–æ“ä½œ
            except Exception as e:  # pragma: no cover
                logger.debug(f"âš ï¸ agent hook æ‰§è¡Œå¤±è´¥: {e}")

        # é¿å…é‡å¤æ³¨å†Œ
        hooks: list = getattr(_AgnoMessage, "_token_monitor_hooks", [])  # type: ignore
        if _agent_hook not in hooks:
            hooks.append(_agent_hook)
            _AgnoMessage._token_monitor_hooks = hooks  # type: ignore
            logger.debug("ğŸ”§ å·²å‘ Message.log æ³¨å†Œå½“å‰ Agent çš„ token ç›‘æ§ hook")


    

    
    def _generate_ai_summary(self, messages_to_summarize) -> str:
        """ç”ŸæˆAIæ€»ç»“å†…å®¹"""
        try:
            # æ„å»ºæ€»ç»“æç¤º
            messages_text = ""
            for i, msg in enumerate(messages_to_summarize):
                role = getattr(msg, 'role', 'unknown')
                content = getattr(msg, 'content', '')
                if content:
                    messages_text += f"{role}: {content[:500]}...\n" if len(content) > 500 else f"{role}: {content}\n"
            
            summary_prompt = f"""è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²æ€»ç»“ä¸ºç®€æ´çš„è¦ç‚¹ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œåˆ†æç»“æœï¼š

{messages_text}

è¯·ç”¨ä¸­æ–‡æ€»ç»“ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
## å¯¹è¯å†å²æ€»ç»“
- ä¸»è¦è®¨è®ºçš„é—®é¢˜ï¼š
- å…³é”®å‘ç°ï¼š
- é‡è¦ç»“è®ºï¼š
- å½“å‰è¿›å±•ï¼š
"""
            
            # è·å–æ€»ç»“æ¨¡å‹
            summary_model = self._get_or_create_summary_model()
            if not summary_model:
                return ""
            
            # è°ƒç”¨AIç”Ÿæˆæ€»ç»“
            from agno.models.message import Message
            summary_messages = [Message(role="user", content=summary_prompt)]
            
            response = summary_model.response(messages=summary_messages)
            if response and hasattr(response, 'content') and response.content:
                return response.content.strip()
            
            return ""
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆAIæ€»ç»“å¤±è´¥: {e}")
            return ""
    
    def _has_pending_tool_calls_in_messages(self):
        """æ£€æŸ¥æœ€è¿‘çš„æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰æœªå®Œæˆçš„å·¥å…·è°ƒç”¨"""
        try:
            # è·å–æœ€æ–°çš„æ¶ˆæ¯åˆ—è¡¨ï¼šä¼˜å…ˆ run_messages.messagesï¼Œå…¶æ¬¡ current_run.messagesï¼Œæœ€å _live_messages
            messages: List = []
            if (
                hasattr(self, "run_messages")
                and self.run_messages is not None
                and getattr(self.run_messages, "messages", None) is not None
            ):
                messages = list(self.run_messages.messages)
            elif hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                messages = list(self.memory.current_run.messages)  # type: ignore
            elif getattr(self, "_live_messages", []):
                messages = list(self._live_messages)
            
            if not messages:
                return False
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåªæ£€æŸ¥æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯ï¼Œé¿å…å†å²æ±¡æŸ“
            # ä»åå¾€å‰æŸ¥æ‰¾æœ€è¿‘çš„assistantæ¶ˆæ¯ï¼ˆåŒ…å«tool_callsï¼‰
            recent_limit = 10  # åªæ£€æŸ¥æœ€è¿‘10æ¡æ¶ˆæ¯
            recent_messages = messages[-recent_limit:] if len(messages) > recent_limit else messages
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªåŒ…å«tool_callsçš„assistantæ¶ˆæ¯
            last_tool_call_msg = None
            last_tool_call_index = -1
            
            for i in range(len(recent_messages) - 1, -1, -1):
                msg = recent_messages[i]
                if (getattr(msg, 'role', '') == 'assistant' and 
                    hasattr(msg, 'tool_calls') and msg.tool_calls):
                    last_tool_call_msg = msg
                    last_tool_call_index = i
                    break
            
            if not last_tool_call_msg:
                # æ²¡æœ‰æ‰¾åˆ°æœ€è¿‘çš„tool_callsï¼Œè¯´æ˜æ²¡æœ‰å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨
                logger.debug("ğŸ”§ æœªæ‰¾åˆ°æœ€è¿‘çš„tool_callsæ¶ˆæ¯")
                return False
            
            # æå–æœ€åä¸€ä¸ªtool_callsæ¶ˆæ¯çš„æ‰€æœ‰tool_call_ids
            expected_tool_call_ids = set()
            try:
                for tc in last_tool_call_msg.tool_calls:
                    if hasattr(tc, 'id'):
                        expected_tool_call_ids.add(tc.id)
                    elif isinstance(tc, dict) and 'id' in tc:
                        expected_tool_call_ids.add(tc['id'])
            except:
                pass
            
            if not expected_tool_call_ids:
                logger.debug("ğŸ”§ æœ€è¿‘çš„tool_callsæ¶ˆæ¯æ²¡æœ‰æœ‰æ•ˆçš„tool_call_id")
                return False
            
            # åœ¨è¯¥assistantæ¶ˆæ¯ä¹‹åæŸ¥æ‰¾å¯¹åº”çš„toolå“åº”
            found_tool_response_ids = set()
            for i in range(last_tool_call_index + 1, len(recent_messages)):
                msg = recent_messages[i]
                if getattr(msg, 'role', '') == 'tool' and hasattr(msg, 'tool_call_id'):
                    if msg.tool_call_id in expected_tool_call_ids:
                        found_tool_response_ids.add(msg.tool_call_id)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰tool_callséƒ½æœ‰å¯¹åº”çš„å“åº”
            pending = expected_tool_call_ids - found_tool_response_ids
            if pending:
                logger.debug(f"ğŸ”§ æœ€è¿‘çš„å·¥å…·è°ƒç”¨ä¸­æœ‰ {len(pending)} ä¸ªæœªå®Œæˆ: {pending}")
                return True
            else:
                logger.debug(f"ğŸ”§ æœ€è¿‘çš„å·¥å…·è°ƒç”¨å·²å…¨éƒ¨å®Œæˆ ({len(expected_tool_call_ids)} ä¸ª)")
                return False
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥æœªå®Œæˆå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            return False

    # ------------------------------------------------------------------
    # ğŸ› ï¸  æ–°å¢: tool æ¶ˆæ¯å‹ç¼© / ä¸¢å¼ƒ è¾…åŠ©æ–¹æ³•
    # ------------------------------------------------------------------
    
    def _truncate_tool_messages_in_run_messages(self):
        """æ™ºèƒ½æˆªæ–­ run_messages ä¸­çš„å·¥å…·æ¶ˆæ¯ï¼Œä¿æŠ¤æœ€è¿‘çš„å·¥å…·è°ƒç”¨"""
        if not (hasattr(self, "run_messages") and self.run_messages and hasattr(self.run_messages, "messages")):
            return
        
        # æ‰¾åˆ°æ‰€æœ‰å·¥å…·æ¶ˆæ¯çš„ç´¢å¼•
        tool_indices = []
        for i, msg in enumerate(self.run_messages.messages):
            if getattr(msg, "role", "") == "tool":
                tool_indices.append(i)
        
        if not tool_indices:
            return
        
        # ä¿æŠ¤æœ€è¿‘çš„ N æ¡å·¥å…·æ¶ˆæ¯
        keep_recent = getattr(self, "keep_recent_tool_messages", 3)
        protected_indices = set(tool_indices[-keep_recent:])
        
        max_len = getattr(self, "max_tool_message_chars", 300)  # æ³¨æ„è¿™é‡Œæ˜¯300ï¼Œä¸æ˜¯10000
        changed = False
        
        for i in tool_indices:
            if i in protected_indices:
                # è·³è¿‡å—ä¿æŠ¤çš„æœ€è¿‘å·¥å…·æ¶ˆæ¯
                continue
                
            msg = self.run_messages.messages[i]
            content = getattr(msg, "content", "")
            if content and len(content) > max_len:
                original_len = len(content)
                msg.content = content[:max_len] + f"\nâ€¦(å†…å®¹è¿‡é•¿å·²æˆªæ–­ï¼ŒåŸé•¿ {original_len} å­—)"
                changed = True
                logger.debug(f"ğŸ”¥ æˆªæ–­æ—§å·¥å…·æ¶ˆæ¯ #{i}: {original_len} -> {len(msg.content)} å­—ç¬¦")
        
        if changed:
            logger.debug(f"ğŸ”¥ å·²æˆªæ–­ run_messages ä¸­çš„æ—§å·¥å…·æ¶ˆæ¯ï¼Œä¿æŠ¤æœ€è¿‘ {keep_recent} æ¡")

    def _compress_old_tool_messages(self) -> bool:
        """å‹ç¼©è¾ƒæ—§ä¸”å†…å®¹è¿‡é•¿çš„ tool æ¶ˆæ¯ï¼Œä¿ç•™æœ€è¿‘Næ¡åŸæ–‡"""
        try:
            # === è°ƒè¯•: å‹ç¼©å‰ç»Ÿè®¡ ===
            _msgs_debug = []
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                _msgs_debug = list(self.memory.current_run.messages)  # type: ignore
            elif getattr(self, "_live_messages", []):
                _msgs_debug = list(self._live_messages)
            tool_cnt_before = sum(1 for _m in _msgs_debug if getattr(_m, "role", "") == "tool")
            tool_chars_before = sum(len(getattr(_m, "content", "")) for _m in _msgs_debug if getattr(_m, "role", "") == "tool")
            logger.debug(f"[TOOL-COMPRESS] before: total_msgs={len(_msgs_debug)}, tool_msgs={tool_cnt_before}, tool_chars={tool_chars_before}")

            # ä¼˜å…ˆä½¿ç”¨ current_run.messagesï¼ˆåŒ…å« tool-msgï¼‰
            msgs = []
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                msgs = list(self.memory.current_run.messages)  # type: ignore
            elif getattr(self, "_live_messages", []):
                msgs = list(self._live_messages)
            if not msgs:
                return False

            # é‡æ–°è®¡ç®— tool ä¸‹æ ‡
            tool_indices = [idx for idx, m in enumerate(msgs) if getattr(m, "role", "") == "tool"]
            protected = set(tool_indices[-self.keep_recent_tool_messages:])
            changed = False
            for idx, msg in enumerate(msgs):
                if idx in protected:
                    continue
                if getattr(msg, "role", "") != "tool":
                    continue
                content = getattr(msg, "content", "")
                if content and len(content) > self.max_tool_message_chars:
                    msg.content = (
                        content[: self.max_tool_message_chars]
                        + f"\nâ€¦(å†…å®¹è¿‡é•¿å·²æˆªæ–­ï¼ŒåŸé•¿ {len(content)} å­—)"
                    )
                    changed = True

            if changed:
                # åŒæ­¥ä¿®æ”¹åçš„åˆ—è¡¨åˆ° _live_messages å’Œ current_run
                self._live_messages = list(msgs)
                if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None) is not None:
                    self.memory.current_run.messages = list(msgs)  # type: ignore
                
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥åˆ° run_messages.messagesï¼ˆæ¨¡å‹å®é™…ä½¿ç”¨çš„åˆ—è¡¨ï¼‰
                if (
                    hasattr(self, "run_messages")
                    and self.run_messages is not None
                    and getattr(self.run_messages, "messages", None) is not None
                ):
                    # æ‰¾åˆ° run_messages ä¸­çš„å·¥å…·æ¶ˆæ¯å¹¶æ›´æ–°
                    for i, run_msg in enumerate(self.run_messages.messages):
                        if getattr(run_msg, "role", "") == "tool":
                            # åœ¨å‹ç¼©åçš„æ¶ˆæ¯ä¸­æ‰¾åˆ°å¯¹åº”çš„å·¥å…·æ¶ˆæ¯
                            for compressed_msg in msgs:
                                if (getattr(compressed_msg, "role", "") == "tool" and 
                                    getattr(compressed_msg, "tool_name", None) == getattr(run_msg, "tool_name", None)):
                                    self.run_messages.messages[i] = compressed_msg
                                    break
                    logger.debug("ğŸ”¥ å·²åŒæ­¥å‹ç¼©ç»“æœåˆ° run_messages.messages")
            return changed

            # === è°ƒè¯•: å‹ç¼©åç»Ÿè®¡ ===
        finally:
            try:
                _msgs_after = []
                if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                    _msgs_after = list(self.memory.current_run.messages)  # type: ignore
                tool_cnt_after = sum(1 for _m in _msgs_after if getattr(_m, "role", "") == "tool")
                tool_chars_after = sum(len(getattr(_m, "content", "")) for _m in _msgs_after if getattr(_m, "role", "") == "tool")
                logger.debug(f"[TOOL-COMPRESS] after : total_msgs={len(_msgs_after)}, tool_msgs={tool_cnt_after}, tool_chars={tool_chars_after}")
            except Exception:
                pass

    def _drop_old_tool_messages(self) -> bool:
        """åˆ é™¤æ›´æ—§çš„ tool æ¶ˆæ¯ï¼Œä»…ä¿ç•™æœ€è¿‘Næ¡ï¼Œç”¨äºå‹ç¼©ä»ä¸è¶³æ—¶å…œåº•"""
        try:
            # === è°ƒè¯•: åˆ é™¤å‰ç»Ÿè®¡ ===
            _msgs_before = []
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                _msgs_before = list(self.memory.current_run.messages)  # type: ignore
            elif getattr(self, "_live_messages", []):
                _msgs_before = list(self._live_messages)
            tool_cnt_before = sum(1 for _m in _msgs_before if getattr(_m, "role", "") == "tool")
            logger.debug(f"[TOOL-DROP] before: total_msgs={len(_msgs_before)}, tool_msgs={tool_cnt_before}")

            # è¯»å–å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
            msgs = []
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                msgs = list(self.memory.current_run.messages)  # type: ignore
            elif getattr(self, "_live_messages", []):
                msgs = list(self._live_messages)
            if not msgs:
                return False

            tool_indices = [idx for idx, m in enumerate(msgs) if getattr(m, "role", "") == "tool"]
            if len(tool_indices) <= self.keep_recent_tool_messages:
                return False  # æ²¡æœ‰å¯åˆ é™¤çš„

            protected = set(tool_indices[-self.keep_recent_tool_messages:])
            new_msgs = [m for idx, m in enumerate(msgs) if not (idx in tool_indices and idx not in protected)]

            if len(new_msgs) == len(msgs):
                return False  # æ— å˜åŠ¨

            # æ›´æ–°ç¼“å†² & current_run
            self._live_messages = new_msgs
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None) is not None:
                self.memory.current_run.messages = list(new_msgs)  # type: ignore
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåŒæ­¥åˆ é™¤åˆ° run_messages.messages
            if (
                hasattr(self, "run_messages")
                and self.run_messages is not None
                and getattr(self.run_messages, "messages", None) is not None
            ):
                # é‡å»º run_messages.messagesï¼Œç§»é™¤è¢«åˆ é™¤çš„å·¥å…·æ¶ˆæ¯
                tool_indices_to_remove = set(tool_indices) - protected
                new_run_msgs = [
                    msg for i, msg in enumerate(self.run_messages.messages)
                    if not (getattr(msg, "role", "") == "tool" and i in tool_indices_to_remove)
                ]
                self.run_messages.messages[:] = new_run_msgs  # åŸåœ°ä¿®æ”¹åˆ—è¡¨
                logger.debug("ğŸ”¥ å·²åŒæ­¥åˆ é™¤ç»“æœåˆ° run_messages.messages")
            
            logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤ {len(msgs) - len(new_msgs)} æ¡æ—§ tool æ¶ˆæ¯ï¼Œä»…ä¿ç•™æœ€è¿‘ {self.keep_recent_tool_messages} æ¡")
            # === è°ƒè¯•: åˆ é™¤åç»Ÿè®¡ ===
            tool_cnt_after = sum(1 for _m in new_msgs if getattr(_m, "role", "") == "tool")
            logger.debug(f"[TOOL-DROP] after : total_msgs={len(new_msgs)}, tool_msgs={tool_cnt_after}")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ tool æ¶ˆæ¯å¤±è´¥: {e}")
            return False

    def _get_or_create_summary_model(self):
        """è·å–æˆ–åˆ›å»ºç”¨äºAIæ€»ç»“çš„ç‹¬ç«‹æ¨¡å‹å®ä¾‹ï¼Œé¿å…ä¸ä¸»Agentæµç¨‹å†²çª"""
        try:
            # å¦‚æœå·²ç»æœ‰ç¼“å­˜çš„æ€»ç»“æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨
            if hasattr(self, '_summary_model') and self._summary_model:
                return self._summary_model
            
            # åˆ›å»ºç‹¬ç«‹çš„æ¨¡å‹å®ä¾‹
            if hasattr(self, 'model') and self.model:
                # è·å–ä¸»æ¨¡å‹çš„é…ç½®
                model_class = type(self.model)
                model_config = {}
                
                # å¤åˆ¶ä¸»è¦é…ç½®å‚æ•°
                if hasattr(self.model, 'id'):
                    model_config['id'] = self.model.id
                if hasattr(self.model, 'api_key'):
                    model_config['api_key'] = self.model.api_key
                if hasattr(self.model, 'base_url'):
                    model_config['base_url'] = self.model.base_url
                if hasattr(self.model, 'temperature'):
                    model_config['temperature'] = getattr(self.model, 'temperature', 0.7)
                if hasattr(self.model, 'max_tokens'):
                    model_config['max_tokens'] = getattr(self.model, 'max_tokens', None)
                
                # å¤åˆ¶è¶…æ—¶æ—¶é—´å’Œé‡è¯•æ¬¡æ•°ï¼Œè‹¥ä¸»æ¨¡å‹æœªè®¾ç½®åˆ™ç»™äºˆå®½æ¾é»˜è®¤
                if hasattr(self.model, 'timeout') and getattr(self.model, 'timeout', None):
                    model_config['timeout'] = getattr(self.model, 'timeout')
                else:
                    model_config['timeout'] = 60
                if hasattr(self.model, 'max_retries') and getattr(self.model, 'max_retries', None):
                    model_config['max_retries'] = getattr(self.model, 'max_retries')
                else:
                    model_config['max_retries'] = 5
                
                # ä¸ºæ€»ç»“æ¨¡å‹åˆ›å»ºä¸“ç”¨ httpx.Client å¹¶å¼€å¯äº‹ä»¶è°ƒè¯•
                try:
                    import httpx, sys

                    def _dbg(name):
                        def _handler(event):
                            print(f"[SUMMARY-HTTPX] {name}: {event!r}", file=sys.stderr)
                        return _handler

                    debug_client = httpx.Client(
                        timeout=model_config.get('timeout', 60),
                        http2=True,  # ä½¿ç”¨ HTTP/2 å¹¶ä¿ç•™ keep-aliveï¼Œé¿å…æœåŠ¡ç«¯æå‰æ–­å¼€
                        event_hooks={
                            "request": [_dbg("request")],
                            "response": [_dbg("response")],
                        },
                    )
                    model_config['http_client'] = debug_client
                except Exception as _dbg_err:
                    logger.debug(f"âš ï¸ åˆ›å»ºè°ƒè¯• httpx.Client å¤±è´¥: {_dbg_err}")
                
                # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
                self._summary_model = model_class(**model_config)
                logger.debug(f"ğŸ” åˆ›å»ºç‹¬ç«‹æ€»ç»“æ¨¡å‹å®ä¾‹: {model_class.__name__}({model_config})")
                return self._summary_model
            else:
                # å¦‚æœæ²¡æœ‰ä¸»æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                from agno.models.openai import OpenAIChat
                self._summary_model = OpenAIChat(id="gpt-4o-mini")  # ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæ€»ç»“
                logger.debug("ğŸ” åˆ›å»ºé»˜è®¤æ€»ç»“æ¨¡å‹å®ä¾‹: OpenAIChat(gpt-4o-mini)")
                return self._summary_model
                
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ€»ç»“æ¨¡å‹å®ä¾‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    # TODO(é‡æ„): è®¡åˆ’åœ¨ summarize_context å·¥å…·ç¨³å®šåï¼Œåˆ é™¤æ—§çš„ _ai_summarize_history_with_context_protection å®ç°
    def _ai_summarize_history_with_context_protection(self) -> bool:
        """ä½¿ç”¨AIæ¨¡å‹æ€»ç»“å†å²å¯¹è¯ï¼Œä½†ä¿æŠ¤å½“å‰å·¥ä½œä¸Šä¸‹æ–‡ï¼ˆé€‚ç”¨äºæŒç»­å·¥å…·è°ƒç”¨åœºæ™¯ï¼‰"""
        try:
            # è·å–å½“å‰æ¶ˆæ¯åˆ—è¡¨ï¼šä¼˜å…ˆ run_messages.messagesï¼Œå…¶æ¬¡ current_run.messagesï¼Œæœ€å _live_messages
            msgs: List = []
            if (
                hasattr(self, "run_messages")
                and self.run_messages is not None
                and getattr(self.run_messages, "messages", None) is not None
            ):
                msgs = list(self.run_messages.messages)
            elif hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None):
                msgs = list(self.memory.current_run.messages)
            elif getattr(self, "_live_messages", []):
                msgs = list(self._live_messages)
            
            if len(msgs) <= 5:  # æ¶ˆæ¯å¤ªå°‘ï¼Œä¸éœ€è¦æ€»ç»“
                return False
            
            # ğŸ”¥ æ–°ç­–ç•¥ï¼šä¿æŠ¤æœ€è¿‘çš„æ¶ˆæ¯ + ä¿ç•™æ‰€æœ‰useræ¶ˆæ¯ + æ€»ç»“å…¶ä½™å†å²
            base_protect_count = min(6, max(3, len(msgs) // 4))  # ä¿æŠ¤æœ€è¿‘1/4ï¼Œä¸Šé™6æ¡
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ä¿æŠ¤è¾¹ç•Œä¸ä¼šæ‹†åˆ† assistant(tool_calls)+tool é“¾
            protect_count = self._ensure_tool_call_context_integrity(msgs, base_protect_count)
            if protect_count != base_protect_count:
                logger.debug(
                    f"ğŸ”§ _ensure_tool_call_context_integrity è°ƒæ•´ä¿æŠ¤è¾¹ç•Œ: {base_protect_count} -> {protect_count}"
                )

            # å¦‚æœéœ€è¦ä¿æŠ¤çš„æ¶ˆæ¯æ•°é‡å¤§äºç­‰äºæ€»é•¿åº¦ï¼Œåˆ™æ— éœ€æ‘˜è¦
            if protect_count >= len(msgs):
                logger.debug("ğŸ”§ ä¿æŠ¤æ•°é‡ >= æ€»æ¶ˆæ¯æ•°ï¼Œè·³è¿‡AIæ€»ç»“")
                return False

            # 1) ä¿æŠ¤æœ€è¿‘çš„æ¶ˆæ¯ï¼ˆåŒ…å«å½“å‰å·¥ä½œä¸Šä¸‹æ–‡ï¼‰
            recent_msgs = list(msgs[-protect_count:])

            # 2) ä»å†å²ä¸­æå–æ‰€æœ‰useræ¶ˆæ¯å•ç‹¬ä¿ç•™
            historical_part = msgs[:-protect_count]

            # é‡æ–°è®¡ç®—éœ€è¦ä¿ç•™çš„ user æ¶ˆæ¯ä¸éœ€è¦æ‘˜è¦çš„å†å²æ¶ˆæ¯
            user_msgs_to_keep = [m for m in historical_part if getattr(m, 'role', '') == 'user']
            history_msgs = [m for m in historical_part if getattr(m, 'role', '') != 'user']

            logger.debug(
                f"ğŸ”§ æ¶ˆæ¯åˆ†ç»„: æœ€è¿‘{len(recent_msgs)}æ¡(ä¿æŠ¤) + ä¿ç•™user{len(user_msgs_to_keep)}æ¡ + æ€»ç»“{len(history_msgs)}æ¡"
            )
            
            if not history_msgs:
                logger.debug("ğŸ”§ æ²¡æœ‰éœ€è¦æ€»ç»“çš„å†å²æ¶ˆæ¯ï¼Œè·³è¿‡AIæ€»ç»“")
                return False

            # æ„å»ºæ€»ç»“æç¤º
            history_text = ""
            for i, msg in enumerate(history_msgs):
                role = getattr(msg, 'role', 'unknown')
                content = str(getattr(msg, 'content', ''))[:1000]  # é™åˆ¶é•¿åº¦é¿å…æ€»ç»“è¯·æ±‚è¿‡é•¿
                history_text += f"\n[{role}]: {content}"
            
            summary_prompt = f"""è¯·å°†ä»¥ä¸‹å¯¹è¯å†å²æ€»ç»“ä¸ºä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡800å­—ï¼‰ï¼Œé‡ç‚¹ä¿ç•™å¯¹åç»­å·¥å…·è°ƒç”¨æœ‰ç”¨çš„ä¿¡æ¯ï¼š

{history_text}

è¦æ±‚ï¼š
1. ä¿ç•™æ‰€æœ‰é‡è¦çš„æŠ€æœ¯å‘ç°ã€æ¼æ´ä¿¡æ¯å’Œåˆ†æç»“æœ
2. ä¿ç•™å…³é”®çš„å·¥å…·è°ƒç”¨ç»“æœå’Œæ•°æ®
3. ä¿ç•™é‡è¦çš„å†³ç­–ã€ç»“è®ºå’Œä¸‹ä¸€æ­¥è®¡åˆ’
4. ä¿ç•™å¯èƒ½å½±å“åç»­åˆ†æçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
5. æŒ‰ä¸»é¢˜åˆ†ç±»ç»„ç»‡ä¿¡æ¯ï¼ˆè€Œéæ—¶é—´é¡ºåºï¼‰
6. çªå‡ºé‡ç‚¹ï¼Œä½†ä¿æŒè¶³å¤Ÿçš„æŠ€æœ¯ç»†èŠ‚ä¾›åç»­å‚è€ƒ

æ³¨æ„ï¼šè¿™ä¸ªæ‘˜è¦å°†ç”¨äºæ”¯æŒåç»­çš„è‡ªä¸»å·¥å…·è°ƒç”¨ï¼Œè¯·ç¡®ä¿åŒ…å«è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"""

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ¯æ¬¡éƒ½åˆ›å»ºå…¨æ–°çš„æ¨¡å‹å®ä¾‹ï¼Œé¿å…è¿æ¥çŠ¶æ€é—®é¢˜
            # æ¸…é™¤ç¼“å­˜çš„æ¨¡å‹å®ä¾‹
            if hasattr(self, '_summary_model'):
                delattr(self, '_summary_model')
            
            summary_model = self._get_or_create_summary_model()
            if not summary_model:
                logger.warning("âš ï¸ æ— æ³•è·å–æ€»ç»“æ¨¡å‹å®ä¾‹ï¼Œè·³è¿‡AIæ€»ç»“")
                return False
            
            logger.info(f"ğŸ¤– å¼€å§‹AIæ€»ç»“å†å²å¯¹è¯ï¼ˆ{len(history_msgs)}æ¡æ¶ˆæ¯ -> 1æ¡æ‘˜è¦ï¼Œä¿æŠ¤æœ€è¿‘{len(user_msgs_to_keep)}æ¡åŒ…å«çœŸå®ç”¨æˆ·æ¶ˆæ¯ï¼‰")
            
            # åˆ›å»ºæ€»ç»“æ¶ˆæ¯
            from agno.models.message import Message
            summary_request = Message(role="user", content=summary_prompt)
            
            # è°ƒç”¨ç‹¬ç«‹æ¨¡å‹ç”Ÿæˆæ€»ç»“
            logger.debug(f"ğŸ” AIæ€»ç»“: ä½¿ç”¨ç‹¬ç«‹æ¨¡å‹å®ä¾‹ {type(summary_model)} è¿›è¡Œæ€»ç»“")
            logger.debug(f"ğŸ” AIæ€»ç»“: æ€»ç»“è¯·æ±‚é•¿åº¦ {len(summary_prompt)} å­—ç¬¦")
            
            # æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†è¿æ¥é”™è¯¯
            max_retries = 3
            retry_delay = 2.0  # å¢åŠ åˆå§‹å»¶è¿Ÿ
            
            for attempt in range(max_retries + 1):
                try:
                    if attempt > 0:
                        logger.info(f"ğŸ”„ AIæ€»ç»“é‡è¯•ç¬¬ {attempt} æ¬¡ï¼Œå»¶è¿Ÿ {retry_delay} ç§’")
                        import time
                        time.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    
                    response = summary_model.response([summary_request])
                    logger.debug(f"ğŸ” AIæ€»ç»“: æ¨¡å‹å“åº”ç±»å‹ {type(response)}")
                    
                    if not response:
                        logger.warning("âš ï¸ AIæ€»ç»“å¤±è´¥ï¼Œæ¨¡å‹è¿”å›None")
                        if attempt < max_retries:
                            continue
                        return False
                        
                    if not hasattr(response, 'content') or not response.content:
                        logger.warning(f"âš ï¸ AIæ€»ç»“å¤±è´¥ï¼Œå“åº”æ— å†…å®¹: {response}")
                        if attempt < max_retries:
                            continue
                        return False
                        
                    logger.debug(f"ğŸ” AIæ€»ç»“: å“åº”å†…å®¹é•¿åº¦ {len(response.content)} å­—ç¬¦")
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    
                except Exception as model_err:
                    import traceback, sys
                    print("=== SUMMARY CALL EXCEPTION ===", file=sys.stderr)
                    traceback.print_exception(type(model_err), model_err, model_err.__traceback__, file=sys.stderr)

                    _ca = getattr(model_err, "__cause__", None) or getattr(model_err, "__context__", None)
                    if _ca:
                        print("â”€â”€ inner cause â”€â”€", file=sys.stderr)
                        traceback.print_exception(type(_ca), _ca, _ca.__traceback__, file=sys.stderr)
                    print("=== END ===", file=sys.stderr)
                    # æ›´ç²¾ç¡®çš„å¼‚å¸¸ç±»å‹åˆ¤æ–­
                    error_msg = str(model_err).lower()
                    error_type = type(model_err).__name__.lower()
                    
                    # åªæœ‰çœŸæ­£çš„è¿æ¥ç›¸å…³å¼‚å¸¸æ‰é‡è¯•
                    is_connection_error = (
                        'connection' in error_msg or 
                        'timeout' in error_msg or 
                        'network' in error_msg or
                        'connectionerror' in error_type or
                        'timeouterror' in error_type or
                        'httperror' in error_type
                    )
                    
                    # æ’é™¤ä¸åº”è¯¥é‡è¯•çš„æƒ…å†µ
                    is_auth_error = 'auth' in error_msg or 'unauthorized' in error_msg or '401' in error_msg
                    is_rate_limit = 'rate limit' in error_msg or '429' in error_msg
                    is_model_error = 'model' in error_msg and 'not found' in error_msg
                    
                    should_retry = is_connection_error and not (is_auth_error or is_rate_limit or is_model_error)
                    
                    if should_retry and attempt < max_retries:
                        logger.warning(f"âš ï¸ AIæ€»ç»“è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries + 1}): {model_err}")
                        import time
                        time.sleep(2.0 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                        continue
                    else:
                        logger.error(f"âŒ AIæ€»ç»“æ¨¡å‹è°ƒç”¨å¤±è´¥: {model_err}")
                        logger.error(f"   é”™è¯¯ç±»å‹: {type(model_err)}")
                        logger.error(f"   é”™è¯¯æ¶ˆæ¯: {error_msg}")
                        logger.error(f"   æ˜¯å¦è¿æ¥é”™è¯¯: {is_connection_error}")
                        logger.error(f"   æ˜¯å¦åº”è¯¥é‡è¯•: {should_retry}")
                        logger.error(f"   å°è¯•æ¬¡æ•°: {attempt + 1}/{max_retries + 1}")
                        
                        if attempt == max_retries:
                            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å› False è®©ä¸Šå±‚ä½¿ç”¨ä¼ ç»Ÿæˆªæ–­
                            logger.warning("âš ï¸ AIæ€»ç»“å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæˆªæ–­")
                            return False
            else:
                # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
                logger.error("âŒ AIæ€»ç»“æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
                return False
            
            # åˆ›å»ºæ€»ç»“æ¶ˆæ¯
            summary_content = f"""
ğŸ“‹ **å†å²ä¸Šä¸‹æ–‡æ‘˜è¦** (å‹ç¼©äº†{len(history_msgs)}æ¡æ¶ˆæ¯ï¼Œä¿æŠ¤äº†æœ€è¿‘{len(user_msgs_to_keep)}æ¡)
å‹ç¼©æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

{response.content}

âš ï¸ **æ³¨æ„**: 
- è¿™æ˜¯ä¸ºæ”¯æŒæŒç»­å·¥å…·è°ƒç”¨è€Œç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ‘˜è¦
- æœ€è¿‘{len(user_msgs_to_keep)}æ¡æ¶ˆæ¯ä¿æŒå®Œæ•´ï¼ŒåŒ…å«çœŸå®ç”¨æˆ·æ¶ˆæ¯å’Œå½“å‰å·¥ä½œä¸Šä¸‹æ–‡
- è¯¦ç»†çš„HCAå†å²è®°å½•å¯é€šè¿‡ query_hca_history() å·¥å…·æŸ¥è¯¢
"""
            
            # ğŸ”¥ æ–°é€»è¾‘ï¼šæ„å»ºæœ€ç»ˆæ¶ˆæ¯åˆ—è¡¨ = useræ¶ˆæ¯ + æ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯
            from agno.models.message import Message
            summary_msg = Message(role="assistant", content=summary_content)
            new_msgs = user_msgs_to_keep + [summary_msg] + recent_msgs
            
            # æ›´æ–°æ‰€æœ‰æ¶ˆæ¯å­˜å‚¨ä½ç½®
            self._live_messages = new_msgs
            if hasattr(self.memory, "current_run") and getattr(self.memory.current_run, "messages", None) is not None:
                self.memory.current_run.messages = new_msgs
            
            # åŒæ­¥åˆ° run_messagesï¼ˆå…³é”®ï¼ï¼‰
            if (hasattr(self, "run_messages") and self.run_messages is not None and 
                getattr(self.run_messages, "messages", None) is not None):
                self.run_messages.messages[:] = new_msgs  # åŸåœ°æ›¿æ¢
            
            # æ›´æ–°ç»Ÿè®¡
            self.session_state.setdefault("context_management", {})
            ctx_mgmt = self.session_state["context_management"]
            ctx_mgmt["ai_summary_count"] = ctx_mgmt.get("ai_summary_count", 0) + 1
            ctx_mgmt["last_ai_summary_time"] = datetime.now().isoformat()
            
            logger.info(f"âœ… AIæ€»ç»“å®Œæˆ: {len(msgs)} -> {len(new_msgs)} æ¡æ¶ˆæ¯ (ä¿ç•™{len(user_msgs_to_keep)}æ¡user + 1æ¡æ‘˜è¦ + {len(recent_msgs)}æ¡æœ€è¿‘)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ AIæ€»ç»“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _create_summarized_messages(self, history_msgs, recent_msgs, summary_content, protect_count):
        """åˆ›å»ºåŒ…å«æ‘˜è¦çš„æ¶ˆæ¯åˆ—è¡¨ï¼šæ™ºèƒ½é‡æ’ç¡®ä¿tool_callsåœ¨æœ€å"""
        from agno.models.message import Message
        
        # åˆ›å»ºæ‘˜è¦æ¶ˆæ¯
        summary_msg = Message(role="assistant", content=summary_content)
        
        logger.debug(f"ğŸ”§ åˆ›å»ºæ‘˜è¦æ¶ˆæ¯åˆ—è¡¨: å†å²{len(history_msgs)}æ¡ -> æ‘˜è¦1æ¡, ä¿æŠ¤æœ€æ–°{len(recent_msgs)}æ¡")
        
        if not recent_msgs:
            # å¦‚æœæ²¡æœ‰æœ€æ–°æ¶ˆæ¯éœ€è¦ä¿æŠ¤ï¼Œåªè¿”å›æ‘˜è¦
            return [summary_msg]
        
        # ğŸ”¥ æœ€ç®€å•æœ‰æ•ˆçš„ç­–ç•¥ï¼šæ‘˜è¦ä½œä¸ºuseræ¶ˆæ¯æ’å…¥ï¼Œé¿å…è¿ç»­assistantæ¶ˆæ¯
        # æ ¸å¿ƒåŸåˆ™ï¼šOpenAI APIä¸å…è®¸è¿ç»­çš„assistantæ¶ˆæ¯
        
        if not recent_msgs:
            result = [summary_msg]
        else:
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªä¿æŠ¤æ¶ˆæ¯çš„è§’è‰²
            first_msg_role = getattr(recent_msgs[0], 'role', '')
            
            if first_msg_role == 'assistant':
                # å¦‚æœç¬¬ä¸€ä¸ªä¿æŠ¤æ¶ˆæ¯æ˜¯assistantï¼Œæ‘˜è¦æ”¹ä¸ºuserè§’è‰²é¿å…å†²çª
                logger.debug("ğŸ”§ æ£€æµ‹åˆ°ä¿æŠ¤æ¶ˆæ¯ä»¥assistantå¼€å¤´ï¼Œæ‘˜è¦æ”¹ä¸ºuserè§’è‰²")
                from agno.models.message import Message
                user_summary_msg = Message(
                    role="user", 
                    content=f"[ä¸Šä¸‹æ–‡æ‘˜è¦] {summary_content}"
                )
                result = [user_summary_msg] + recent_msgs
            else:
                # å…¶ä»–æƒ…å†µï¼Œæ‘˜è¦ä¿æŒassistantè§’è‰²
                logger.debug("ğŸ”§ ä¿æŠ¤æ¶ˆæ¯ä¸ä»¥assistantå¼€å¤´ï¼Œæ‘˜è¦ä¿æŒassistantè§’è‰²")
                result = [summary_msg] + recent_msgs
        
        logger.debug(f"ğŸ”§ æ‘˜è¦æ¶ˆæ¯åˆ—è¡¨åˆ›å»ºå®Œæˆ: æ€»è®¡{len(result)}æ¡æ¶ˆæ¯")
        logger.debug(f"ğŸ”§ æœ€ç»ˆæ¶ˆæ¯é¡ºåº: {[getattr(msg, 'role', 'unknown') for msg in result]}")
        
        return result
    
    def _has_incomplete_tool_calls(self, msgs):
        """æ£€æŸ¥æ¶ˆæ¯åˆ—è¡¨ä¸­æ˜¯å¦æœ‰ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨"""
        tool_call_ids = set()
        tool_response_ids = set()
        
        for msg in msgs:
            role = getattr(msg, 'role', '')
            
            # æ”¶é›†æ‰€æœ‰çš„tool_call_ids
            if role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls:
                try:
                    for tc in msg.tool_calls:
                        if hasattr(tc, 'id'):
                            tool_call_ids.add(tc.id)
                        elif isinstance(tc, dict) and 'id' in tc:
                            tool_call_ids.add(tc['id'])
                except:
                    pass
            
            # æ”¶é›†æ‰€æœ‰çš„toolå“åº”ids
            elif role == 'tool' and hasattr(msg, 'tool_call_id'):
                tool_response_ids.add(msg.tool_call_id)
        
        # å¦‚æœæœ‰tool_callsä½†æ²¡æœ‰å¯¹åº”çš„å“åº”ï¼Œå°±æ˜¯ä¸å®Œæ•´çš„
        incomplete = tool_call_ids - tool_response_ids
        if incomplete:
            logger.debug(f"ğŸ”§ å‘ç°ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨: {incomplete}")
            return True
        
        return False
    
    def _repair_incomplete_tool_calls_in_recent(self, recent_msgs):
        """ä¿®å¤æœ€æ–°æ¶ˆæ¯ä¸­çš„ä¸å®Œæ•´å·¥å…·è°ƒç”¨"""
        from agno.models.message import Message
        
        result = []
        pending_tool_calls = {}  # tool_call_id -> assistant_msg
        
        for msg in recent_msgs:
            role = getattr(msg, 'role', '')
            
            if role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls:
                # è®°å½•è¿™ä¸ªassistantæ¶ˆæ¯çš„tool_calls
                result.append(msg)
                try:
                    for tc in msg.tool_calls:
                        tool_call_id = None
                        if hasattr(tc, 'id'):
                            tool_call_id = tc.id
                        elif isinstance(tc, dict) and 'id' in tc:
                            tool_call_id = tc['id']
                        
                        if tool_call_id:
                            pending_tool_calls[tool_call_id] = msg
                except:
                    pass
            
            elif role == 'tool' and hasattr(msg, 'tool_call_id'):
                # è¿™æ˜¯ä¸€ä¸ªtoolå“åº”ï¼Œç§»é™¤å¯¹åº”çš„pending
                result.append(msg)
                if msg.tool_call_id in pending_tool_calls:
                    del pending_tool_calls[msg.tool_call_id]
            
            else:
                # å…¶ä»–æ¶ˆæ¯ç›´æ¥æ·»åŠ 
                result.append(msg)
        
        # ä¸ºæ‰€æœ‰pendingçš„tool_callsåˆ›å»ºè™šæ‹Ÿå“åº”
        for tool_call_id, assistant_msg in pending_tool_calls.items():
            virtual_response = Message(
                role="tool",
                content="[ä¸Šä¸‹æ–‡ä¼˜åŒ–ï¼šå·¥å…·è°ƒç”¨å·²å®Œæˆï¼Œç»“æœå·²æ•´åˆåˆ°å†å²æ‘˜è¦ä¸­]",
                tool_call_id=tool_call_id
            )
            result.append(virtual_response)
            logger.debug(f"ğŸ”§ ä¸ºtool_call_id {tool_call_id} åˆ›å»ºè™šæ‹Ÿå“åº”")
        
        return result
    

    

    

    

    
    def _has_tool_call_context(self, msgs):
        """æ£€æŸ¥æ¶ˆæ¯åˆ—è¡¨ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡"""
        for msg in msgs:
            if (hasattr(msg, 'tool_calls') and msg.tool_calls) or getattr(msg, 'role', '') == 'tool':
                return True
        return False
    
    def _find_assistant_with_tool_calls(self, msgs):
        """åœ¨æ¶ˆæ¯åˆ—è¡¨ä¸­æ‰¾åˆ°åŒ…å«tool_callsçš„assistantæ¶ˆæ¯çš„ç´¢å¼•"""
        for i, msg in enumerate(msgs):
            if (getattr(msg, 'role', '') == 'assistant' and 
                hasattr(msg, 'tool_calls') and msg.tool_calls):
                return i
        return -1
    
    def _find_last_real_user_message(self, msgs):
        """æ‰¾åˆ°æœ€åä¸€ä¸ªçœŸå®çš„ç”¨æˆ·æ¶ˆæ¯ç´¢å¼•"""
        for i in range(len(msgs) - 1, -1, -1):
            if msgs[i].role == "user" and not getattr(msgs[i], 'from_history', False):
                return i
        return -1
    
    def _ensure_tool_call_context_integrity(self, messages: List, target_keep_count: int) -> int:
        """
        ç¡®ä¿å·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ï¼Œè°ƒæ•´ä¿ç•™æ¶ˆæ¯æ•°é‡
        
        è§„åˆ™ï¼š
        1. å¦‚æœä¿ç•™çš„æ¶ˆæ¯ä¸­æœ‰ assistant æ¶ˆæ¯åŒ…å« tool_callsï¼Œå¿…é¡»ä¿ç•™å¯¹åº”çš„ tool æ¶ˆæ¯
        2. å¦‚æœä¿ç•™çš„æ¶ˆæ¯ä¸­æœ‰ tool æ¶ˆæ¯ï¼Œå¿…é¡»ä¿ç•™å¯¹åº”çš„ assistant æ¶ˆæ¯
        3. ç¡®ä¿å·¥å…·è°ƒç”¨é“¾çš„å®Œæ•´æ€§
        4. ğŸ”¥ ç‰¹åˆ«ä¿æŠ¤ï¼šæ£€æµ‹æ­£åœ¨æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ï¼Œç¡®ä¿ä¸è¢«æˆªæ–­
        """
        if target_keep_count >= len(messages):
            return target_keep_count
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šé¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ï¼ˆæœ€åä¸€æ¡assistantæ¶ˆæ¯åŒ…å«tool_callsä½†æ²¡æœ‰å¯¹åº”çš„toolå“åº”ï¼‰
        # ä»åå¾€å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªassistantæ¶ˆæ¯
        last_assistant_idx = -1
        logger.debug(f"ğŸ” å·¥å…·è°ƒç”¨å®Œæ•´æ€§æ£€æŸ¥ï¼šå¼€å§‹æ£€æŸ¥ {len(messages)} æ¡æ¶ˆæ¯")
        for i in range(len(messages) - 1, -1, -1):
            msg = messages[i]
            role = getattr(msg, 'role', '')
            has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
            logger.debug(f"ğŸ” æ¶ˆæ¯ #{i}: role={role}, has_tool_calls={has_tool_calls}")
            if role == 'assistant' and has_tool_calls:
                last_assistant_idx = i
                logger.debug(f"ğŸ” æ‰¾åˆ°æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨assistantæ¶ˆæ¯: #{i}")
                break
        
        if last_assistant_idx != -1:
            # æ£€æŸ¥è¿™ä¸ªassistantæ¶ˆæ¯çš„tool_callsæ˜¯å¦éƒ½æœ‰å¯¹åº”çš„toolå“åº”
            assistant_msg = messages[last_assistant_idx]
            tool_call_ids = set()
            try:
                for tc in assistant_msg.tool_calls:
                    if hasattr(tc, 'id'):
                        tool_call_ids.add(tc.id)
                    elif isinstance(tc, dict) and 'id' in tc:
                        tool_call_ids.add(tc['id'])
            except:
                pass
            
            logger.debug(f"ğŸ” å·¥å…·è°ƒç”¨IDs: {tool_call_ids}")
            
            if tool_call_ids:
                # æ£€æŸ¥åç»­æ˜¯å¦æœ‰å¯¹åº”çš„toolå“åº”
                found_tool_responses = set()
                for i in range(last_assistant_idx + 1, len(messages)):
                    msg = messages[i]
                    msg_role = getattr(msg, 'role', '')
                    tool_call_id = getattr(msg, 'tool_call_id', None)
                    logger.debug(f"ğŸ” æ£€æŸ¥æ¶ˆæ¯ #{i}: role={msg_role}, tool_call_id={tool_call_id}")
                    if (msg_role == 'tool' and 
                        hasattr(msg, 'tool_call_id') and 
                        msg.tool_call_id in tool_call_ids):
                        found_tool_responses.add(msg.tool_call_id)
                        logger.debug(f"ğŸ” æ‰¾åˆ°å·¥å…·å“åº”: {msg.tool_call_id}")
                
                logger.debug(f"ğŸ” æ‰¾åˆ°çš„å·¥å…·å“åº”: {found_tool_responses}")
                
                # å¦‚æœæœ‰æœªå®Œæˆçš„å·¥å…·è°ƒç”¨ï¼Œå¿…é¡»ä¿ç•™è¿™ä¸ªassistantæ¶ˆæ¯åŠå…¶åç»­æ‰€æœ‰æ¶ˆæ¯
                pending_tool_calls = tool_call_ids - found_tool_responses
                logger.debug(f"ğŸ” æœªå®Œæˆçš„å·¥å…·è°ƒç”¨: {pending_tool_calls}")
                if pending_tool_calls:
                    needed_count = len(messages) - last_assistant_idx
                    logger.debug(f"ğŸ” éœ€è¦ä¿ç•™æ¶ˆæ¯æ•°: {needed_count}, å½“å‰ç›®æ ‡ä¿ç•™æ•°: {target_keep_count}")
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ— è®ºéœ€è¦ä¿ç•™çš„æ¶ˆæ¯æ•°æ˜¯å¦å¤§äºç›®æ ‡æ•°ï¼Œéƒ½è¦ç¡®ä¿å®Œæ•´æ€§
                    if needed_count > target_keep_count:
                        logger.warning(f"ğŸ”¥ æ£€æµ‹åˆ°æ­£åœ¨æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ {pending_tool_calls}ï¼Œå¼ºåˆ¶ä¿ç•™ {needed_count} æ¡æ¶ˆæ¯")
                        target_keep_count = needed_count
                    else:
                        # å³ä½¿needed_countè¾ƒå°ï¼Œä¹Ÿè¦ç¡®ä¿ä¸ç ´åå·¥å…·è°ƒç”¨é“¾
                        logger.warning(f"ğŸ”¥ æ£€æµ‹åˆ°æ­£åœ¨æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ {pending_tool_calls}ï¼Œä¿æŒå½“å‰ä¿ç•™æ•°é‡ {target_keep_count}")
                        # éªŒè¯å½“å‰ä¿ç•™æ•°é‡æ˜¯å¦è¶³å¤ŸåŒ…å«å®Œæ•´çš„å·¥å…·è°ƒç”¨é“¾
                        if last_assistant_idx < len(messages) - target_keep_count:
                            # å¦‚æœassistantæ¶ˆæ¯ä¸åœ¨ä¿ç•™èŒƒå›´å†…ï¼Œå¼ºåˆ¶è°ƒæ•´
                            target_keep_count = len(messages) - last_assistant_idx
                            logger.warning(f"ğŸ”¥ è°ƒæ•´ä¿ç•™æ•°é‡ä»¥åŒ…å«å®Œæ•´å·¥å…·è°ƒç”¨é“¾: {target_keep_count}")
                else:
                    logger.debug(f"ğŸ” æ‰€æœ‰å·¥å…·è°ƒç”¨éƒ½å·²å®Œæˆ")
        else:
            logger.debug(f"ğŸ” æœªæ‰¾åˆ°ä»»ä½•å·¥å…·è°ƒç”¨assistantæ¶ˆæ¯")
        
        # åˆ†æä» target_keep_count å¼€å§‹çš„æ¶ˆæ¯
        start_idx = len(messages) - target_keep_count
        kept_messages = messages[start_idx:]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸å®Œæ•´çš„å·¥å…·è°ƒç”¨
        adjusted_keep_count = target_keep_count
        
        # å‘å‰æ‰«æï¼Œå¯»æ‰¾å¯èƒ½è¢«æˆªæ–­çš„å·¥å…·è°ƒç”¨é“¾
        for i in range(max(0, start_idx - 10), start_idx):  # å‘å‰æ£€æŸ¥æœ€å¤š10æ¡æ¶ˆæ¯
            msg = messages[i]
            role = getattr(msg, 'role', '')
            
            # å¦‚æœå‘ç° assistant æ¶ˆæ¯åŒ…å« tool_calls
            if role == 'assistant' and hasattr(msg, 'tool_calls') and msg.tool_calls:
                # æ£€æŸ¥åç»­çš„ tool æ¶ˆæ¯æ˜¯å¦åœ¨ä¿ç•™èŒƒå›´å†…
                tool_call_ids = []
                try:
                    for tc in msg.tool_calls:
                        if hasattr(tc, 'id'):
                            tool_call_ids.append(tc.id)
                        elif isinstance(tc, dict) and 'id' in tc:
                            tool_call_ids.append(tc['id'])
                except:
                    continue
                
                if tool_call_ids:
                    # æ£€æŸ¥å¯¹åº”çš„ tool æ¶ˆæ¯æ˜¯å¦åœ¨ä¿ç•™èŒƒå›´å†…
                    tool_messages_in_kept = []
                    for j in range(i + 1, len(messages)):
                        next_msg = messages[j]
                        if (getattr(next_msg, 'role', '') == 'tool' and 
                            hasattr(next_msg, 'tool_call_id') and 
                            next_msg.tool_call_id in tool_call_ids):
                            tool_messages_in_kept.append(j)
                    
                    # å¦‚æœæœ‰ tool æ¶ˆæ¯åœ¨ä¿ç•™èŒƒå›´å†…ï¼Œéœ€è¦ä¿ç•™è¿™ä¸ª assistant æ¶ˆæ¯
                    if any(j >= start_idx for j in tool_messages_in_kept):
                        needed_count = len(messages) - i
                        if needed_count > adjusted_keep_count:
                            adjusted_keep_count = needed_count
                            logger.debug(f"ğŸ”§ å‘ç°ä¸å®Œæ•´å·¥å…·è°ƒç”¨é“¾ï¼Œæ‰©å±•ä¿ç•™èŒƒå›´åˆ° {adjusted_keep_count}")
        
        # æ£€æŸ¥ä¿ç•™æ¶ˆæ¯çš„å¼€å¤´æ˜¯å¦æœ‰å­¤ç«‹çš„ tool æ¶ˆæ¯
        if kept_messages:
            first_msg = kept_messages[0]
            if getattr(first_msg, 'role', '') == 'tool':
                # å‘å‰å¯»æ‰¾å¯¹åº”çš„ assistant æ¶ˆæ¯
                tool_call_id = getattr(first_msg, 'tool_call_id', None)
                if tool_call_id:
                    for i in range(start_idx - 1, max(0, start_idx - 10), -1):
                        msg = messages[i]
                        if (getattr(msg, 'role', '') == 'assistant' and 
                            hasattr(msg, 'tool_calls') and msg.tool_calls):
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯¹åº”çš„ tool_call_id
                            for tc in msg.tool_calls:
                                tc_id = getattr(tc, 'id', None) or (tc.get('id') if isinstance(tc, dict) else None)
                                if tc_id == tool_call_id:
                                    needed_count = len(messages) - i
                                    if needed_count > adjusted_keep_count:
                                        adjusted_keep_count = needed_count
                                        logger.debug(f"ğŸ”§ å‘ç°å­¤ç«‹ tool æ¶ˆæ¯ï¼Œæ‰©å±•ä¿ç•™èŒƒå›´åˆ° {adjusted_keep_count}")
                                    break
                            break
        
        # ç¡®ä¿ä¸è¶…è¿‡æ€»æ¶ˆæ¯æ•°
        return min(adjusted_keep_count, len(messages))

    def _truncate_context_messages(self, force: bool = False) -> bool:
        """æˆªæ–­æ—©æœŸçš„ä¸Šä¸‹æ–‡æ¶ˆæ¯ï¼Œä¿ç•™æœ€æ–°çš„éƒ¨åˆ†"""
        try:
            # --- è‹¥å­˜åœ¨æœªå®Œæˆçš„å·¥å…·è°ƒç”¨é“¾ï¼Œè·³è¿‡æˆªæ–­ä»¥å…ç ´åå®Œæ•´æ€§ ---
            try:
                if (not force) and self._has_pending_tool_calls_in_messages():
                    logger.debug("ğŸ›‘ æ£€æµ‹åˆ°æœªå®Œæˆçš„ tool è°ƒç”¨é“¾ï¼Œæš‚ä¸æˆªæ–­ä»¥ä¿æŒä¸Šä¸‹æ–‡å®Œæ•´")
                    return False
            except Exception:
                pass

            # --- ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥ä½¿ç”¨å½“å‰è¿è¡Œä¸­çš„æ¶ˆæ¯åˆ—è¡¨ ---
            # åœ¨è¿è¡Œä¸­çš„ run å†…éƒ¨ï¼Œç›´æ¥ä½¿ç”¨ run_messages.messages
            messages = None
            
            # ä¼˜å…ˆä½¿ç”¨å½“å‰è¿è¡Œçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆæœ€å‡†ç¡®ã€æœ€å®Œæ•´ï¼‰
            if hasattr(self, 'run_messages') and self.run_messages and hasattr(self.run_messages, 'messages'):
                messages = self.run_messages.messages
                logger.debug(f"ğŸ” >>> ä½¿ç”¨å½“å‰è¿è¡Œçš„ run_messages.messages: {len(messages)}æ¡æ¶ˆæ¯")
            else:
                # å›é€€åˆ° memory å­˜å‚¨
                if not hasattr(self, 'memory') or not self.memory:
                    logger.warning("âš ï¸ æ— æ³•è®¿é—®memoryå’Œrun_messagesï¼Œè·³è¿‡æˆªæ–­")
                    return False
                
                # æ£€æŸ¥Memoryç±»å‹å¹¶è·å–æ¶ˆæ¯
                if hasattr(self.memory, 'messages'):
                    # æ—§ç‰ˆAgentMemory
                    messages = self.memory.messages
                    logger.debug(f"ğŸ” >>> å›é€€ä½¿ç”¨AgentMemory.messages: {len(messages) if messages else 0}æ¡æ¶ˆæ¯")
                else:
                    logger.warning("âš ï¸ æ— æ³•è·å–å½“å‰è¿è¡Œçš„æ¶ˆæ¯åˆ—è¡¨ï¼Œè·³è¿‡æˆªæ–­")
                    return False
            
            if not messages:
                logger.warning("âš ï¸ æ¶ˆæ¯åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æˆªæ–­")
                return False
            
            # è®¡ç®—è¦ä¿ç•™çš„æ¶ˆæ¯æ•°é‡
            total_messages = len(messages)
            keep_count = int(total_messages * self.keep_ratio)
            if keep_count < 1:
                keep_count = 1
            
            logger.debug(f"ğŸ” >>> æˆªæ–­å‰: {total_messages}æ¡æ¶ˆæ¯ï¼Œä¿ç•™: {keep_count}æ¡")
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿å·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡å®Œæ•´æ€§
            # è°ƒæ•´ keep_count ä»¥ä¿æŠ¤å®Œæ•´çš„å·¥å…·è°ƒç”¨é“¾
            adjusted_keep_count = self._ensure_tool_call_context_integrity(messages, keep_count)
            if adjusted_keep_count != keep_count:
                logger.info(f"ğŸ”§ ä¸ºä¿æŠ¤å·¥å…·è°ƒç”¨ä¸Šä¸‹æ–‡ï¼Œè°ƒæ•´ä¿ç•™æ•°é‡: {keep_count} -> {adjusted_keep_count}")
                keep_count = adjusted_keep_count
            
            # ä¿å­˜è¢«æˆªæ–­çš„æ—§æ¶ˆæ¯ä»¥ç”Ÿæˆæ‘˜è¦
            truncated_messages = messages[:-keep_count]

            # æ‰§è¡Œæˆªæ–­å¹¶åŒæ­¥åˆ°å½“å‰è¿è¡Œçš„æ¶ˆæ¯åˆ—è¡¨
            kept_msgs = messages[-keep_count:]

            # ç”Ÿæˆæ‘˜è¦å¹¶æ’å…¥æœ€å‰é¢ï¼Œä¾›åç»­æ¨¡å‹å‚è€ƒ
            if truncated_messages:
                summary_msg = self._create_truncation_summary(truncated_messages, len(truncated_messages))
                kept_msgs.insert(0, summary_msg)
                
            # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥ä¿®æ”¹å½“å‰è¿è¡Œçš„æ¶ˆæ¯åˆ—è¡¨
            if hasattr(self, 'run_messages') and self.run_messages and hasattr(self.run_messages, 'messages'):
                self.run_messages.messages[:] = kept_msgs  # åŸåœ°æ›¿æ¢
                logger.debug("ğŸ”¥ å·²æˆªæ–­å¹¶æ›´æ–° run_messages.messages")
            else:
                # å›é€€ï¼šä¿®æ”¹ memory.messagesï¼ˆé€‚ç”¨äºæ—§ç‰ˆ AgentMemoryï¼‰
                if hasattr(self.memory, 'messages'):
                    self.memory.messages = kept_msgs
                    logger.debug("ğŸ”¥ å·²æˆªæ–­å¹¶å›é€€æ›´æ–° memory.messages")
                else:
                    logger.error("âŒ æ— æ³•æ‰¾åˆ°å¯ä¿®æ”¹çš„æ¶ˆæ¯åˆ—è¡¨")
                    return False
            
            # æ›´æ–°æˆªæ–­ç»Ÿè®¡
            self.session_state['context_management']['truncation_count'] = \
                self.session_state['context_management'].get('truncation_count', 0) + 1
            self.session_state['context_management']['last_truncation_time'] = \
                datetime.now().isoformat()
            
            logger.info(f"âœ‚ï¸ æ‰§è¡Œæˆªæ–­: {total_messages} -> {keep_count} æ¡æ¶ˆæ¯ï¼Œå·²ç”Ÿæˆæ‘˜è¦æ¶ˆæ¯")

            return True
            
        except Exception as e:
            logger.error(f"âŒ æˆªæ–­å¤±è´¥: {e}")
            return False
    

 