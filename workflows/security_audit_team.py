import asyncio
import os
import uuid
from textwrap import dedent
from typing import AsyncIterator, List, Optional, Dict, Any

from agno.agent import Agent
from agno.run.response import RunResponse
from agno.memory.v2.db.sqlite import SqliteMemoryDb
from agno.memory.v2.memory import Memory
from agno.team import Team
from agno.tools.file import FileTools
from agno.tools.shell import ShellTools
from agno.media import Image

from core.model_factory import get_model_instance, DEFAULT_MODEL_ID
from agents.environment_perception_agent import (
    DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_CONFIG,
    DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_ID
)
from agents.attack_surface_identification_agent import (
    ATTACK_SURFACE_PLANNING_AGENT_CONFIG, # This is the _v2_whitebox version
    ATTACK_SURFACE_PLANNING_AGENT_ID
)
from agents.deep_dive_security_auditor_agent import (
    DEEP_DIVE_SECURITY_AUDITOR_AGENT_CONFIG,
    DEEP_DIVE_SECURITY_AUDITOR_AGENT_ID
)
from tools.report_repository_tools import (
    save_report_to_repository,
    read_report_from_repository,
    SHARED_REPORTS_DIR
)

# --- Report Filenames Constants ---
DEPLOYMENT_REPORT_FILENAME = "DeploymentArchitectureReport.md"
PLAN_FILENAME = "AttackSurfaceInvestigationPlan_whitebox.md" # Generated by Planner Agent
AGGREGATED_DEEP_DIVE_FILENAME_PREFIX = "DeepDiveAuditFindings_Aggregated" # Full report at the end
INDIVIDUAL_DEEP_DIVE_REPORT_PREFIX = "DeepDiveReport_Task" # For individual task reports from Auditor Agent

# --- Team Definition ---
SECURITY_AUDIT_TEAM_ID = "security_audit_team_v1"
SECURITY_AUDIT_TEAM_NAME = "SecurityAuditTeam"
SECURITY_AUDIT_TEAM_DESCRIPTION = dedent((
    "A coordinated team of AI agents designed to perform a multi-stage security audit. "
    "Stage 1: Environment Perception. Stage 2: Attack Surface Planning. Stage 3: Deep-Dive Auditing."
))

# --- Team Leader (Team itself) Instructions ---
# This will be the most complex part and will be refined.
TEAM_LEADER_INSTRUCTIONS = dedent(f'''
You are the Team Leader of the Security Audit Team. Your goal is to orchestrate a three-stage security audit of a software project based on an initial user query.

**Project Shared Directory:**
All reports are saved and read from: `{SHARED_REPORTS_DIR}`.
Ensure all agents use this path correctly.

**Report Filenames:**
- Stage 1 (Environment Reporter) output: `{DEPLOYMENT_REPORT_FILENAME}`
- Stage 2 (Attack Planner) output: `{PLAN_FILENAME}` (This plan will contain Markdown checkboxes for tasks: `- [ ] Task Description`)
- Stage 3 (Deep Dive Auditor) individual task reports will be named like: `{INDIVIDUAL_DEEP_DIVE_REPORT_PREFIX}_[task_id_or_name].md`
- Your final aggregated report of all deep dive findings: `{AGGREGATED_DEEP_DIVE_FILENAME_PREFIX}_[timestamp].md`

**Your Tools:**
- You have `FileTools` to read the `{PLAN_FILENAME}` and to modify it by checking off completed tasks.

**Workflow:**

**Phase 0: Initial Setup**
- You will receive an initial user query. This query should be passed to the relevant agents as context.

**Phase 1: Environment Perception**
1.  Invoke the `{DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_ID}`.
2.  Its task is to analyze the project (context provided by the user query and its own tools if needed) and produce a `{DEPLOYMENT_REPORT_FILENAME}`.
3.  Ensure it saves this report to `{SHARED_REPORTS_DIR}/{DEPLOYMENT_REPORT_FILENAME}` using its `save_report_to_repository` tool.
4.  Confirm the report is saved.

**Phase 2: Attack Surface Planning**
1.  Invoke the `{ATTACK_SURFACE_PLANNING_AGENT_ID}`.
2.  Its task is to:
    a. Read the `{DEPLOYMENT_REPORT_FILENAME}` (from `{SHARED_REPORTS_DIR}/{DEPLOYMENT_REPORT_FILENAME}`) using its `read_report_from_repository` tool.
    b. Consider the original user query.
    c. Create a detailed, white-box code review plan named `{PLAN_FILENAME}`. This plan **MUST** use Markdown checkboxes for each actionable audit item (e.g., `- [ ] Review authentication logic in xyz.java`).
    d. Save this plan to `{SHARED_REPORTS_DIR}/{PLAN_FILENAME}` using its `save_report_to_repository` tool.
3.  Confirm the plan is saved.

**Phase 3: Iterative Deep-Dive Auditing & Reporting**
1.  Initialize an empty list or string to accumulate findings for the final aggregated report.
2.  **Loop Start:**
    a. Read the content of `{SHARED_REPORTS_DIR}/{PLAN_FILENAME}` using your `FileTools.read_file`.
    b. Parse this file to find the *first* uncompleted task (i.e., a line starting with `- [ ]`).
    c. **If no uncompleted tasks are found:** The loop is complete. Proceed to Phase 4.
    d. **If an uncompleted task is found:**
        i.  Extract the task description. Let's call this `current_audit_task`.
        ii. Invoke the `{DEEP_DIVE_SECURITY_AUDITOR_AGENT_ID}`.
        iii. Provide it with `current_audit_task` as its primary instruction, and also pass along the original user query for broader context.
        iv. The `{DEEP_DIVE_SECURITY_AUDITOR_AGENT_ID}` will perform its deep dive and produce a Markdown report for this specific task.
        v.  Collect this report content. Append it to your accumulating list/string for the final aggregated report. (Optionally, you can also save this individual report to `{SHARED_REPORTS_DIR}/{INDIVIDUAL_DEEP_DIVE_REPORT_PREFIX}_[unique_task_identifier].md` for record-keeping, using your `FileTools.edit_file` to create/write it).
        vi. **Crucially**: Modify the `{SHARED_REPORTS_DIR}/{PLAN_FILENAME}` using `FileTools.edit_file`. Find the line for `current_audit_task` (e.g., `- [ ] The task description`) and change it to be completed (e.g., `- [x] The task description`). Make sure to preserve the rest of the file content. This is critical for tracking progress.
        vii. Go back to **Loop Start** (step 2a).

**Phase 4: Final Aggregation and Output**
1.  Once all tasks in `{PLAN_FILENAME}` are marked as completed.
2.  Compile all the collected individual deep-dive reports into a single, comprehensive Markdown document.
3.  Save this aggregated report as `{SHARED_REPORTS_DIR}/{AGGREGATED_DEEP_DIVE_FILENAME_PREFIX}_[timestamp].md` using `FileTools.edit_file`. (Generate a unique timestamp for the filename).
4.  Your final output message should indicate the process is complete and point to the location of all generated reports, especially the aggregated one.

Be methodical. Ensure each step completes successfully before moving to the next. Pay close attention to file paths and tool usage.
If an agent fails or a step cannot be completed, report the issue clearly.
''')


class SecurityAuditTeam:
    def __init__(self, model_id: str = DEFAULT_MODEL_ID, db_path: str = "team_memory.sqlite"):
        self.model_id = model_id
        self.db_path = db_path
        self._setup_team()

    def _setup_team(self):
        # Get model instances
        team_leader_model = get_model_instance(self.model_id)
        env_reporter_model = get_model_instance(self.model_id)
        planner_model = get_model_instance(self.model_id)
        auditor_model = get_model_instance(self.model_id)

        # 1. Environment Reporter Agent
        env_perception_agent = Agent(
            name=DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_CONFIG.name,
            description=DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_CONFIG.description,
            instructions=DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_CONFIG.instructions,
            tools=DEPLOYMENT_ARCHITECTURE_REPORTER_AGENT_CONFIG.tools + [save_report_to_repository],
            model=env_reporter_model,
        )

        # 2. Attack Surface Planning Agent
        attack_planning_agent = Agent(
            name=ATTACK_SURFACE_PLANNING_AGENT_CONFIG.name,
            description=ATTACK_SURFACE_PLANNING_AGENT_CONFIG.description,
            instructions=ATTACK_SURFACE_PLANNING_AGENT_CONFIG.instructions,
            tools=ATTACK_SURFACE_PLANNING_AGENT_CONFIG.tools + [read_report_from_repository, save_report_to_repository],
            model=planner_model,
        )

        # 3. Deep Dive Security Auditor Agent
        auditor_file_tools = FileTools()
        auditor_shell_tools = ShellTools()
        deep_dive_auditor = Agent(
            name=DEEP_DIVE_SECURITY_AUDITOR_AGENT_CONFIG.name,
            description=DEEP_DIVE_SECURITY_AUDITOR_AGENT_CONFIG.description,
            instructions=DEEP_DIVE_SECURITY_AUDITOR_AGENT_CONFIG.instructions_template,
            tools=[auditor_file_tools, auditor_shell_tools, read_report_from_repository],
            model=auditor_model,
        )
        # Ensure FileTools and ShellTools are available to the agent.
        # The AgentConfig already lists FileTools and ShellTools as classes.
        # Agno should instantiate them. If not, we might need to pass instances.

        # Team Leader (the Team itself) tools
        team_leader_file_tools = FileTools() # Instantiate FileTools
        
        # Memory
        if os.path.exists(self.db_path):
            os.remove(self.db_path) # Clean slate for demo purposes
        
        # Create the SQLite database backend
        sqlite_db_backend = SqliteMemoryDb(db_file=self.db_path, table_name="team_memory_table")
        # Create the main Memory object, wrapping the SQLite backend
        team_main_memory = Memory(db=sqlite_db_backend)


        self.team = Team(
            team_id=SECURITY_AUDIT_TEAM_ID,
            name=SECURITY_AUDIT_TEAM_NAME,
            description=SECURITY_AUDIT_TEAM_DESCRIPTION,
            model=team_leader_model,
            instructions=TEAM_LEADER_INSTRUCTIONS,
            members=[env_perception_agent, attack_planning_agent, deep_dive_auditor],
            tools=[team_leader_file_tools], # Pass the FileTools instance
            mode="coordinate",
            memory=team_main_memory, # Pass the wrapped Memory object
            enable_team_history=True,
            share_member_interactions=False,
            enable_agentic_context=True,
            markdown=True,  # Assuming markdown is desired for outputs
            debug_mode=True,
            show_tool_calls=True,
            show_members_responses=True,
            # enable_user_memories=True, # Might be redundant if team_history & member_context are on
        )

    async def stream_team_audit(
        self,
        initial_user_query: str,
        run_id: Optional[str] = None,
        session_id: Optional[str] = None,
        images: Optional[List[Image]] = None,
    ) -> AsyncIterator[RunResponse]:
        if not run_id:
            run_id = f"run_{uuid.uuid4()}"
        if not session_id:
            session_id = f"session_{uuid.uuid4()}"

        print(f"Starting Team Audit with Run ID: {run_id}, Session ID: {session_id}")
        print(f"Initial User Query: {initial_user_query}")
        print(f"Reports will be saved in: {SHARED_REPORTS_DIR}")
        os.makedirs(SHARED_REPORTS_DIR, exist_ok=True)

        # Clear previous reports for a clean run (optional, for demo)
        # for f_name in [DEPLOYMENT_REPORT_FILENAME, PLAN_FILENAME]:
        #     f_path = os.path.join(SHARED_REPORTS_DIR, f_name)
        #     if os.path.exists(f_path):
        #         os.remove(f_path)
        # for f_name in os.listdir(SHARED_REPORTS_DIR):
        #     if f_name.startswith(AGGREGATED_DEEP_DIVE_FILENAME_PREFIX) or f_name.startswith(INDIVIDUAL_DEEP_DIVE_REPORT_PREFIX):
        #         os.remove(os.path.join(SHARED_REPORTS_DIR, f_name))


        async for response_chunk in await self.team.arun(
            message=initial_user_query,
            run_id=run_id,
            session_id=session_id,
            images=images,
            stream=True,
            # stream_tool_calls=True # To see tool calls from the leader/members
        ):
            yield response_chunk
        print(f"Team Audit Run ID {run_id} completed.")

async def main():
    # Example of how to run the team
    # Ensure OPENROUTER_API_KEY is set in your environment
    # And vulnagent8.core.model_factory is configured for OpenRouter or your desired model provider

    # Create a dummy project structure and files for testing if needed
    # For example:
    # os.makedirs("../data/mall_code_test/src", exist_ok=True)
    # with open("../data/mall_code_test/src/main.py", "w") as f:
    #     f.write("print('Hello from main.py')")
    # with open("../data/mall_code_test/pom.xml", "w") as f:
    #     f.write("<project><version>1.0.0</version></project>")

    print(f"Shared reports will be in: {os.path.abspath(SHARED_REPORTS_DIR)}")

    audit_team = SecurityAuditTeam(model_id="openrouter/google/gemini-2.5-flash-preview-05-20") # or your preferred model
    
    test_query = "Perform a security audit of the provided project. The project is a simple Python application with a pom.xml file. Identify potential vulnerabilities."
    # More specific query for a real project:
    # test_query = "Audit the 'mall' project located in /data/code. Focus on its Java Spring Boot microservices (mall-admin, mall-portal, mall-search) and their interactions, paying attention to authentication, authorization, input validation, and data handling for common web vulnerabilities. The project uses Nginx as a reverse proxy and various backing services like MySQL, MongoDB, Redis, Elasticsearch, and RabbitMQ, as detailed in its docker-compose files."


    print("\n--- Streaming Team Audit ---")
    async for chunk in audit_team.stream_team_audit(initial_user_query=test_query):
        if chunk.event == "on_agent_action_end" and chunk.run_id == audit_team.team.id : # or chunk.run_id.startswith("agt_")
             if chunk.data and chunk.data.get("output"):
                print(f"\n[Team Log Stream] Event: {chunk.event}, Agent: {chunk.run_id}")
                print(f"Content: {chunk.data.get('output')[:500]}...") # Print first 500 chars
        elif chunk.event == "on_tool_use":
            print(f"\n[Team Log Stream] Event: {chunk.event}, Agent: {chunk.run_id}, Tool: {chunk.data.get('name')}")
            if chunk.data.get("input"): print(f"Tool Input: {chunk.data.get('input')}")
        elif chunk.event == "on_tool_end":
             print(f"\n[Team Log Stream] Event: {chunk.event}, Agent: {chunk.run_id}, Tool: {chunk.data.get('name')}")
             if chunk.data.get("output"): print(f"Tool Output: {chunk.data.get('output')[:300]}...")
        elif chunk.event == "on_agent_stream_chunk":
            if chunk.run_id == audit_team.team.id: # only print stream from Team Leader
                 print(chunk.data.get("output_chunk", ""), end="", flush=True)

    print("\n--- Team Audit Complete ---")
    print(f"Final reports should be in: {SHARED_REPORTS_DIR}")
    print("Check for files like:")
    print(f"- {DEPLOYMENT_REPORT_FILENAME}")
    print(f"- {PLAN_FILENAME}")
    print(f"- Files starting with {INDIVIDUAL_DEEP_DIVE_REPORT_PREFIX}")
    print(f"- Files starting with {AGGREGATED_DEEP_DIVE_FILENAME_PREFIX}")


if __name__ == "__main__":
    # To run this:
    # Ensure OPENROUTER_API_KEY is set if using OpenRouter models.
    # From the root of the 'agno' project (or wherever vulnagent8 is a module):
    # python -m vulnagent8.workflows.security_audit_team
    # asyncio.run(main())

    # For testing with a real project, you might need to adjust paths or mount volumes if running in Docker.
    # The `SHARED_REPORTS_DIR` is currently set relative to `report_repository_tools.py`.
    # We might want to make it absolute or configurable for easier Docker volume mapping.
    # For now, it resolves to `vulnagent8/tools/../../shared_reports` -> `vulnagent8/shared_reports`
    
    # HACK: For running this file directly for dev, adjust Python path
    import sys
    sys.path.append(os.path.join(os.path.dirname(__file__), '../..')) #  Adds 'agno' (parent of 'vulnagent8') to path
    
    asyncio.run(main()) 