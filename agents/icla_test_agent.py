from textwrap import dedent
from typing import Optional, Callable, Dict, Any
import json
from datetime import datetime
import os
from pathlib import Path

from agno.agent import Agent
from agno.models.openai import OpenAIChat, OpenAILike
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.shell import ShellTools
from agno.tools.file import FileTools
from agno.tools import tool
from agno.utils.pprint import pprint_run_response

from db.session import db_url

# ç¡¬ç¼–ç çš„å·¥ä½œç©ºé—´è·¯å¾„
HARDCODED_WORKSPACE_PATH = Path("/data/one-api")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
if not OPENROUTER_API_KEY:
    raise ValueError("OPENROUTER_API_KEY is not set")

# ====== æ–°æ¶æ„ï¼šçŠ¶æ€é€æ˜å·¥å…· ======

@tool
def view_current_state(agent: Agent) -> str:
    """æŸ¥çœ‹å½“å‰HCAçŠ¶æ€å’Œè¿›åº¦ - å®Œæ•´çŠ¶æ€ä¿¡æ¯ï¼ˆå› ä¸ºå·¥å…·è°ƒç”¨æ—¶çœ‹ä¸åˆ°session_stateï¼‰"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    working_memory = agent.session_state["working_memory"]
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    current_challenge = runtime_state.get("current_challenge", {})
    current_adaptation = runtime_state.get("current_adaptation", {})
    
    # è·å–ä¸‹ä¸€æ­¥å»ºè®®
    next_action = "åˆ†æä»£ç ï¼Œè°ƒç”¨ start_new_hypothesis('å…·ä½“å‡è®¾å†…å®¹')"
    if current_hypothesis:
        status = current_hypothesis.get('status', '')
        if status == 'pending_challenge':
            next_action = "è°ƒç”¨ record_challenge('ç±»å‹', 'åé©³è¯æ®å†…å®¹')"
        elif status == 'challenged':
            next_action = "è°ƒç”¨ complete_adaptation('è°ƒæ•´å†…å®¹', 'æ¨ç†è¿‡ç¨‹')"
        elif status == 'adapted':
            next_action = "å¯ä»¥å¼€å§‹æ–°å‡è®¾æˆ–è°ƒç”¨ validate_conclusion_readiness()"
    
    # å®Œæ•´çš„çŠ¶æ€è¾“å‡ºï¼ˆæ›¿ä»£session_stateè‡ªåŠ¨æ³¨å…¥ï¼‰
    result = f"""ğŸ“Š **å®Œæ•´ICLAçŠ¶æ€è§†å›¾**

ğŸ”¬ **å½“å‰å‡è®¾** (H-{runtime_state.get('hypothesis_count', 1):02d}):
- ID: {current_hypothesis.get('id', 'å°šæœªåˆ›å»º')}
- çŠ¶æ€: {current_hypothesis.get('status', 'N/A')}
- åˆ›å»ºæ—¶é—´: {current_hypothesis.get('created_at', 'N/A')}
- å†…å®¹: {current_hypothesis.get('content', 'å°šæœªè®¾ç½®')}

âš”ï¸ **å½“å‰æŒ‘æˆ˜**:
- ç±»å‹: {current_challenge.get('type', 'N/A')}
- çŠ¶æ€: {current_challenge.get('status', 'N/A')}
- å†…å®¹: {current_challenge.get('content', 'N/A')}
- æ—¶é—´: {current_challenge.get('timestamp', 'N/A')}

ğŸ§  **å½“å‰é€‚åº”**:
- çŠ¶æ€: {current_adaptation.get('status', 'N/A')}
- å˜åŒ–: {current_adaptation.get('changes', 'N/A')}
- æ¨ç†: {current_adaptation.get('reasoning', 'N/A')}

ğŸ“ˆ **æ•´ä½“è¿›åº¦**:
- å½“å‰é˜¶æ®µ: {runtime_state.get('current_phase', 'hypothesis')}
- å‡è®¾è®¡æ•°: {runtime_state.get('hypothesis_count', 1)}
- ç´¯ç§¯å¥–åŠ±: {agent.session_state.get('cumulative_reward', 0.0):.2f}
- æ€»æ­¥æ•°: {agent.session_state.get('total_steps', 0)}
- å·¥ä½œè®°å¿†å¤§å°: {len(agent.session_state.get('main_md_content', ''))} å­—ç¬¦

ğŸ“š **HCAå†å²**:
- å·²å®Œæˆå¾ªç¯æ•°: {len(working_memory.get('hca_history', []))}

ğŸ¯ **å½“å‰çŠ¶æ€åˆ¤æ–­**:
- å½“å‰å‡è®¾å¯ç”¨äºç»“è®º: {'âœ…' if current_hypothesis.get('status') == 'adapted' else 'âŒ'}
- å»ºè®®ä¸‹ä¸€æ­¥è¡ŒåŠ¨: {next_action}

âš ï¸ **é‡è¦æé†’**: 
- åªæœ‰çŠ¶æ€ä¸º'adapted'çš„å‡è®¾æ‰èƒ½ç”¨äºå½¢æˆæœ€ç»ˆç»“è®º
- å¿…é¡»å®Œæ•´ç»è¿‡ Hâ†’Câ†’A æµç¨‹"""
    
    return result

@tool
def view_hca_history(agent: Agent) -> str:
    """æŸ¥çœ‹HCAå†å²å¾ªç¯è®°å½• - å®Œæ•´å†å²ä¿¡æ¯ï¼ˆå·¥å…·è°ƒç”¨æ—¶æ— æ³•è®¿é—®session_stateï¼‰"""
    _ensure_state_structure(agent)
    
    working_memory = agent.session_state["working_memory"]
    hca_history = working_memory.get("hca_history", [])
    
    if not hca_history:
        return "ğŸ“š **HCAå†å²**: æš‚æ— å®Œæˆçš„HCAå¾ªç¯è®°å½•\n\nâš ï¸ è¿™æ„å‘³ç€è¿˜æ²¡æœ‰ä»»ä½•å‡è®¾å®Œæˆå®Œæ•´çš„Hâ†’Câ†’Aæµç¨‹"
    
    result = f"ğŸ“š **å®Œæ•´HCAå†å²è®°å½•** (å…±{len(hca_history)}ä¸ªå¾ªç¯):\n\n"
    
    # æ˜¾ç¤ºæ‰€æœ‰å¾ªç¯çš„è¯¦ç»†ä¿¡æ¯
    for i, cycle in enumerate(hca_history, 1):
        result += f"**å¾ªç¯ {cycle.get('cycle_id', f'#{i}')} - {cycle.get('completed_at', 'N/A')}**:\n"
        result += f"- å‡è®¾: {cycle.get('hypothesis', 'N/A')}\n"
        result += f"- æŒ‘æˆ˜ç±»å‹: {cycle.get('challenge_type', 'N/A')}\n"
        result += f"- æŒ‘æˆ˜å†…å®¹: {cycle.get('challenge_content', 'N/A')}\n"
        result += f"- é€‚åº”å˜åŒ–: {cycle.get('adaptation_changes', 'N/A')}\n"
        result += f"- é€‚åº”æ¨ç†: {cycle.get('adaptation_reasoning', 'N/A')}\n"
        result += f"- çŠ¶æ€: {cycle.get('status', 'N/A')}\n"
        result += "---\n"
    
    # æ·»åŠ å­¦ä¹ æ´å¯Ÿ
    learning_insights = working_memory.get("learning_insights", [])
    if learning_insights:
        result += f"\nğŸ’¡ **å­¦ä¹ æ´å¯Ÿ** (å…±{len(learning_insights)}æ¡):\n"
        for insight in learning_insights[-3:]:  # æ˜¾ç¤ºæœ€è¿‘3æ¡
            result += f"- {insight}\n"
    
    result += f"\nğŸ”¢ **ç»Ÿè®¡æ‘˜è¦**:\n"
    result += f"- å®Œæˆçš„å‡è®¾æ•°: {len(hca_history)}\n"
    result += f"- å­¦ä¹ æ´å¯Ÿæ•°: {len(learning_insights)}\n"
    result += f"- å¯ç”¨äºç»“è®ºçš„å‡è®¾: {len([h for h in hca_history if h.get('status') == 'completed'])}ä¸ª"
    
    return result

# ====== æ–°æ¶æ„ï¼šçŠ¶æ€æ›´æ–°å·¥å…· ======

@tool
def start_new_hypothesis(agent: Agent, content: str) -> str:
    """å¼€å§‹æ–°å‡è®¾ - ä»£ç†è‡ªä¸»å†³å®šä½•æ—¶ä½¿ç”¨"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    hypothesis_count = runtime_state["hypothesis_count"]
    
    # åˆ›å»ºæ–°å‡è®¾
    new_hypothesis = {
        "id": f"H-{hypothesis_count:02d}",
        "content": content,
        "created_at": datetime.now().isoformat(),
        "status": "pending_challenge"
    }
    
    runtime_state["current_hypothesis"] = new_hypothesis
    runtime_state["current_phase"] = "hypothesis"
    
    # æ›´æ–°å·¥ä½œè®°å¿†
    agent.session_state["main_md_content"] = _update_main_md_with_hypothesis(agent, content)
    agent.session_state["total_steps"] = agent.session_state.get("total_steps", 0) + 1
    
    # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
    is_valid, error_msg = _validate_state_consistency(agent)
    if not is_valid:
        return f"âŒ **çŠ¶æ€é”™è¯¯**: {error_msg}"
    
    return f"""ğŸ”¬ **æ–°å‡è®¾å·²åˆ›å»º**: H-{hypothesis_count:02d}
    
ğŸ“‹ **å‡è®¾å†…å®¹**: {content}
âš ï¸ **çŠ¶æ€**: pending_challenge (æ— æ³•ç”¨äºç»“è®º)
ğŸ¯ **ä¸‹ä¸€æ­¥**: å¿…é¡»è¿›å…¥æŒ‘æˆ˜é˜¶æ®µæ‰èƒ½ç”¨äºç»“è®ºå½¢æˆ

ğŸ’¡ **æ¼æ´åˆ†ææé†’**: ç¡®ä¿å‡è®¾å…·ä½“æŒ‡å‘å¯èƒ½çš„å®‰å…¨æ¼æ´ç‚¹"""

@tool
def record_challenge(agent: Agent, challenge_type: str, content: str) -> str:
    """è®°å½•æŒ‘æˆ˜å†…å®¹ - å¦‚æœè¦å½¢æˆç»“è®ºï¼Œæ­¤æ­¥éª¤å¿…é¡»æ‰§è¡Œ"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    
    if not current_hypothesis or current_hypothesis.get("status") != "pending_challenge":
        return "âŒ **é”™è¯¯**: å½“å‰æ²¡æœ‰å¾…æŒ‘æˆ˜çš„å‡è®¾ã€‚è¯·å…ˆè°ƒç”¨ start_new_hypothesis()"
    
    # éªŒè¯challenge_typeæœ‰æ•ˆæ€§
    valid_types = ["assumption", "evidence", "logic", "bias"]
    if challenge_type not in valid_types:
        return f"âŒ **é”™è¯¯**: challenge_typeå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {valid_types}"
    
    # è®°å½•æŒ‘æˆ˜
    challenge = {
        "type": challenge_type,
        "content": content,
        "status": "addressed",
        "timestamp": datetime.now().isoformat()
    }
    
    runtime_state["current_challenge"] = challenge
    runtime_state["current_hypothesis"]["status"] = "challenged"
    runtime_state["current_phase"] = "challenge"
    
    agent.session_state["total_steps"] = agent.session_state.get("total_steps", 0) + 1
    
    # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
    is_valid, error_msg = _validate_state_consistency(agent)
    if not is_valid:
        return f"âŒ **çŠ¶æ€é”™è¯¯**: {error_msg}"
    
    return f"""âš”ï¸ **æŒ‘æˆ˜å·²è®°å½•**: {challenge_type}

ğŸ“‹ **æŒ‘æˆ˜å†…å®¹**: {content}
âœ… **å‡è®¾çŠ¶æ€**: challenged (ä»æ— æ³•ç”¨äºç»“è®º)
ğŸ¯ **ä¸‹ä¸€æ­¥**: å¿…é¡»å®Œæˆé€‚åº”é˜¶æ®µæ‰èƒ½ç”¨äºç»“è®ºå½¢æˆ

ğŸ” **å®‰å…¨åˆ†ææé†’**: æŒ‘æˆ˜åº”å…³æ³¨è¾“å…¥éªŒè¯ã€æƒé™æ£€æŸ¥ã€è¾¹ç•Œæ¡ä»¶ç­‰å®‰å…¨é˜²æŠ¤"""

@tool
def complete_adaptation(agent: Agent, changes: str, reasoning: str) -> str:
    """å®Œæˆé€‚åº” - å¦‚æœè¦å½¢æˆç»“è®ºï¼Œæ­¤æ­¥éª¤å¿…é¡»æ‰§è¡Œ"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    
    if not current_hypothesis or current_hypothesis.get("status") != "challenged":
        return "âŒ **é”™è¯¯**: å½“å‰å‡è®¾æœªç»è¿‡æŒ‘æˆ˜ã€‚è¯·å…ˆè°ƒç”¨ record_challenge()"
    
    # è®°å½•é€‚åº”
    adaptation = {
        "changes": changes,
        "reasoning": reasoning,
        "status": "completed",
        "timestamp": datetime.now().isoformat()
    }
    
    runtime_state["current_adaptation"] = adaptation
    runtime_state["current_hypothesis"]["status"] = "adapted"
    runtime_state["current_phase"] = "adapt"
    
    # è®°å½•åˆ°å†å²
    _record_hca_cycle_to_history(agent)
    
    # å‡†å¤‡ä¸‹ä¸€ä¸ªå‡è®¾
    runtime_state["hypothesis_count"] += 1
    runtime_state["current_phase"] = "hypothesis"
    
    agent.session_state["total_steps"] = agent.session_state.get("total_steps", 0) + 1
    
    # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
    is_valid, error_msg = _validate_state_consistency(agent)
    if not is_valid:
        return f"âŒ **çŠ¶æ€é”™è¯¯**: {error_msg}"
    
    return f"""ğŸ§  **é€‚åº”å·²å®Œæˆ**

ğŸ“‹ **é€‚åº”å˜åŒ–**: {changes}
ğŸ¤” **æ¨ç†è¿‡ç¨‹**: {reasoning}
âœ… **å‡è®¾çŠ¶æ€**: adapted (å¯ç”¨äºç»“è®ºå½¢æˆ)

ğŸ”„ **æµç¨‹çŠ¶æ€**: å‡†å¤‡å¼€å§‹ä¸‹ä¸€ä¸ªå‡è®¾ H-{runtime_state['hypothesis_count']:02d}
ğŸ¯ **æ¼æ´å‘ç°**: å¦‚æœç¡®è®¤å‘ç°æ¼æ´ï¼Œè°ƒç”¨ terminate_with_report()"""

@tool
def validate_conclusion_readiness(agent: Agent) -> str:
    """éªŒè¯æ˜¯å¦å¯ä»¥åŸºäºå½“å‰å‡è®¾å½¢æˆç»“è®º"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    working_memory = agent.session_state["working_memory"]
    
    # æ£€æŸ¥å½“å‰å‡è®¾
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    current_ready = current_hypothesis.get("status") == "adapted"
    current_hypothesis_id = current_hypothesis.get("id", "N/A")
    
    # æ£€æŸ¥å†å²å‡è®¾
    hca_history = working_memory.get("hca_history", [])
    ready_hypotheses = [h for h in hca_history if h.get("status") == "completed"]
    
    # è®¡ç®—æ€»çš„å¯ç”¨å‡è®¾æ•°
    total_ready = len(ready_hypotheses) + (1 if current_ready else 0)
    
    status_message = f"""ğŸ¯ **ç»“è®ºå°±ç»ªæ€§éªŒè¯**

âœ… **å¯ç”¨äºç»“è®ºçš„å‡è®¾** (æ€»è®¡: {total_ready}ä¸ª):
- å½“å‰å‡è®¾: {current_hypothesis_id if current_ready else 'æ— '}
- å†å²å®Œæˆå‡è®¾: {len(ready_hypotheses)}ä¸ª

ğŸ“Š **å½“å‰å‡è®¾çŠ¶æ€**:
- ID: {current_hypothesis_id}
- çŠ¶æ€: {current_hypothesis.get('status', 'N/A')}
- {'âœ… å¯ç”¨äºç»“è®º' if current_ready else 'âŒ æ— æ³•ç”¨äºç»“è®º'}

ğŸš¨ **æµç¨‹å®Œæ•´æ€§**: åªæœ‰adaptedçŠ¶æ€çš„å‡è®¾æ‰èƒ½ç”¨äºæœ€ç»ˆç»“è®º"""

    # ç»™å‡ºå…·ä½“çš„ä¸‹ä¸€æ­¥å»ºè®®
    if current_ready or total_ready > 0:
        status_message += f"\n\nğŸ’¡ **å»ºè®®**: å½“å‰æœ‰{total_ready}ä¸ªå‡è®¾å¯ç”¨äºç»“è®ºï¼Œå¯ä»¥è°ƒç”¨ terminate_with_report()"
    else:
        status_message += f"\n\nâš ï¸ **å»ºè®®**: å°šæ— å¯ç”¨å‡è®¾ï¼Œéœ€è¦å®Œæˆå½“å‰HCAå¾ªç¯æˆ–å¼€å§‹æ–°å‡è®¾"
    
    return status_message

# ====== ä¿ç•™åŸæœ‰æ ¸å¿ƒå·¥å…·ï¼ˆé€‚é…æ–°æ¶æ„ï¼‰======

@tool
def calculate_intrinsic_reward(agent: Agent, information_gain_score: float, reasoning: str) -> str:
    """è®¡ç®—å¹¶è®°å½•å†…åœ¨å¥–åŠ± - ICLA æ ¸å¿ƒæœºåˆ¶"""
    if not 0.0 <= information_gain_score <= 1.0:
        return "âŒ ä¿¡æ¯å¢ç›Šåˆ†æ•°å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´"
    
    current_reward = agent.session_state.get("cumulative_reward", 0.0)
    new_reward = current_reward + information_gain_score
    agent.session_state["cumulative_reward"] = new_reward
    
    if "reward_history" not in agent.session_state:
        agent.session_state["reward_history"] = []
    
    reward_entry = {
        "step": agent.session_state.get("total_steps", 0),
        "score": information_gain_score,
        "reasoning": reasoning,
        "timestamp": datetime.now().isoformat()
    }
    agent.session_state["reward_history"].append(reward_entry)
    
    return f"âœ… å†…åœ¨å¥–åŠ±å·²è®°å½•: +{information_gain_score:.2f} | ç´¯ç§¯å¥–åŠ±: {new_reward:.2f}"

@tool
def terminate_with_report(agent: Agent, final_report: str) -> str:
    """ç»ˆæ­¢ä»»åŠ¡å¹¶æäº¤æœ€ç»ˆæŠ¥å‘Š"""
    agent.session_state["task_completed"] = True
    agent.session_state["final_report"] = final_report
    agent.session_state["completion_time"] = datetime.now().isoformat()
    
    summary = {
        "total_steps": agent.session_state.get("total_steps", 0),
        "cumulative_reward": agent.session_state.get("cumulative_reward", 0.0),
        "final_report": final_report
    }
    
    return f"ğŸ ä»»åŠ¡å·²å®Œæˆï¼\n\n**æœ€ç»ˆæŠ¥å‘Š:**\n{final_report}\n\n**ç»Ÿè®¡:**\n```json\n{json.dumps(summary, indent=2, ensure_ascii=False)}\n```"

@tool
def create_archive_file(agent: Agent, filename: str, content: str) -> str:
    """åˆ›å»ºå½’æ¡£æ–‡ä»¶ - ç”¨äºä¸Šä¸‹æ–‡ç®¡ç†"""
    if "archive_files" not in agent.session_state:
        agent.session_state["archive_files"] = {}
    
    agent.session_state["archive_files"][filename] = {
        "content": content,
        "created_at": datetime.now().isoformat(),
        "step": agent.session_state.get("total_steps", 0)
    }
    
    return f"ğŸ“ å½’æ¡£æ–‡ä»¶å·²åˆ›å»º: {filename} ({len(content)} å­—ç¬¦)"

@tool
def update_main_md(agent: Agent, new_content: str) -> str:
    """ä¼ ç»Ÿå·¥ä½œè®°å¿†æ›´æ–° - å…¼å®¹æ—§æ¥å£ï¼Œå»ºè®®ä½¿ç”¨æ–°æ¶æ„å·¥å…·"""
    agent.session_state["main_md_content"] = new_content
    agent.session_state["last_update_time"] = datetime.now().isoformat()
    agent.session_state["total_steps"] = agent.session_state.get("total_steps", 0) + 1
    
    # ç®€åŒ–çš„ä¸Šä¸‹æ–‡æé†’
    content_length = len(new_content)
    if content_length > 3000:
        pressure_info = f"âš ï¸ ä¸Šä¸‹æ–‡: {content_length} å­—ç¬¦ (è€ƒè™‘å½’æ¡£)"
    else:
        pressure_info = f"ğŸ“Š ä¸Šä¸‹æ–‡: {content_length} å­—ç¬¦"
    
    return f"""âœ… å·¥ä½œè®°å¿†å·²æ›´æ–°
{pressure_info}
ğŸ“ˆ æ­¥æ•°: {agent.session_state['total_steps']} | ç´¯ç§¯å¥–åŠ±: {agent.session_state.get('cumulative_reward', 0.0):.2f}

ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨æ–°æ¶æ„å·¥å…· view_current_state() æŸ¥çœ‹è¯¦ç»†çŠ¶æ€"""

# ====== æ–°æ¶æ„æ”¯æŒå‡½æ•° ======

def _validate_state_consistency(agent: Agent) -> tuple[bool, str]:
    """éªŒè¯çŠ¶æ€ä¸€è‡´æ€§ï¼Œè¿”å›(æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)"""
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    current_challenge = runtime_state.get("current_challenge", {})
    current_adaptation = runtime_state.get("current_adaptation", {})
    current_phase = runtime_state.get("current_phase", "hypothesis")
    
    # æ£€æŸ¥çŠ¶æ€æœºçš„ä¸€è‡´æ€§
    if current_hypothesis:
        hypothesis_status = current_hypothesis.get("status", "")
        
        # çŠ¶æ€å’Œé˜¶æ®µä¸€è‡´æ€§æ£€æŸ¥
        if hypothesis_status == "pending_challenge":
            if current_phase != "hypothesis":
                return False, f"å‡è®¾çŠ¶æ€ä¸ºpending_challengeï¼Œä½†å½“å‰é˜¶æ®µä¸º{current_phase}ï¼Œåº”è¯¥æ˜¯hypothesis"
            if current_challenge:
                return False, "å‡è®¾çŠ¶æ€ä¸ºpending_challengeï¼Œä½†å·²ç»å­˜åœ¨æŒ‘æˆ˜è®°å½•"
                
        elif hypothesis_status == "challenged":
            if current_phase != "challenge":
                return False, f"å‡è®¾çŠ¶æ€ä¸ºchallengedï¼Œä½†å½“å‰é˜¶æ®µä¸º{current_phase}ï¼Œåº”è¯¥æ˜¯challenge"
            if not current_challenge:
                return False, "å‡è®¾çŠ¶æ€ä¸ºchallengedï¼Œä½†æ²¡æœ‰æŒ‘æˆ˜è®°å½•"
                
        elif hypothesis_status == "adapted":
            if current_phase != "adapt":
                return False, f"å‡è®¾çŠ¶æ€ä¸ºadaptedï¼Œä½†å½“å‰é˜¶æ®µä¸º{current_phase}ï¼Œåº”è¯¥æ˜¯adapt"
            if not current_challenge or not current_adaptation:
                return False, "å‡è®¾çŠ¶æ€ä¸ºadaptedï¼Œä½†ç¼ºå°‘æŒ‘æˆ˜æˆ–é€‚åº”è®°å½•"
    
    return True, "çŠ¶æ€ä¸€è‡´"

def _ensure_state_structure(agent: Agent):
    """ç¡®ä¿æ–°æ¶æ„çŠ¶æ€ç»“æ„å­˜åœ¨"""
    if "runtime_state" not in agent.session_state:
        agent.session_state["runtime_state"] = {
            "current_phase": "hypothesis",
            "hypothesis_count": 1,
            "current_hypothesis": {},
            "current_challenge": {},
            "current_adaptation": {},
            "phase_guidance": {}
        }
    
    if "working_memory" not in agent.session_state:
        agent.session_state["working_memory"] = {
            "hca_history": [],
            "learning_insights": [],
            "challenge_patterns": {}
        }

def _update_main_md_with_hypothesis(agent: Agent, hypothesis_content: str) -> str:
    """ä½¿ç”¨å‡è®¾å†…å®¹æ›´æ–°ä¸»å·¥ä½œè®°å¿†"""
    runtime_state = agent.session_state["runtime_state"]
    hypothesis_id = runtime_state["current_hypothesis"]["id"]
    
    existing_content = agent.session_state.get("main_md_content", "")
    
    # æ·»åŠ æ–°å‡è®¾æ®µè½
    new_section = f"""

## Active Hypothesis {hypothesis_id}
**å‡è®¾é™ˆè¿°**: {hypothesis_content}
**åˆ›å»ºæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**çŠ¶æ€**: å¾…æŒ‘æˆ˜ (pending_challenge)

### é¢„æœŸå‘ç°
{hypothesis_content}

### æŒ‘æˆ˜è®°å½•
(å¾…æ›´æ–°)

### é€‚åº”ç»“æœ
(å¾…æ›´æ–°)
"""
    
    return existing_content + new_section

def _record_hca_cycle_to_history(agent: Agent):
    """å°†å®Œæˆçš„HCAå¾ªç¯è®°å½•åˆ°å†å²"""
    runtime_state = agent.session_state["runtime_state"]
    working_memory = agent.session_state["working_memory"]
    
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    current_challenge = runtime_state.get("current_challenge", {})
    current_adaptation = runtime_state.get("current_adaptation", {})
    
    if current_hypothesis and current_challenge and current_adaptation:
        cycle_record = {
            "cycle_id": runtime_state.get("hypothesis_count", 1),
            "hypothesis": current_hypothesis.get("content", ""),
            "challenges": [current_challenge],
            "adaptations": [current_adaptation.get("changes", "")],
            "outcomes": current_adaptation.get("reasoning", ""),
            "status": "completed",
            "timestamp": datetime.now().isoformat()
        }
        
        working_memory["hca_history"].append(cycle_record)
        
        # æ¸…ç†å½“å‰çŠ¶æ€ï¼Œä¸ºä¸‹ä¸€ä¸ªHCAå¾ªç¯å‡†å¤‡
        runtime_state["current_hypothesis"] = {}
        runtime_state["current_challenge"] = {}
        runtime_state["current_adaptation"] = {}

# ====== æ–°æ¶æ„ç¼–æ’é’©å­ ======

def icla_orchestrator_hook(function_name: str, function_call: Callable, arguments: Dict[str, Any]) -> Any:
    """
    æ–°æ¶æ„ICLAåè°ƒå™¨é’©å­ - è½»åº¦ç¼–æ’ï¼Œç¡®ä¿æµç¨‹å®Œæ•´æ€§
    """
    # è°ƒç”¨åŸå§‹å‡½æ•°
    result = function_call(**arguments)
    
    # è·å–agentå®ä¾‹
    agent = arguments.get("agent")
    if not agent:
        return result
    
    # ç¡®ä¿çŠ¶æ€ç»“æ„å­˜åœ¨
    _ensure_state_structure(agent)
    
    runtime_state = agent.session_state["runtime_state"]
    current_phase = runtime_state.get("current_phase", "hypothesis")
    current_hypothesis = runtime_state.get("current_hypothesis", {})
    
    # æ£€æŸ¥HCAæµç¨‹å®Œæ•´æ€§
    incomplete_hypotheses = []
    if current_hypothesis and current_hypothesis.get("status") in ["pending_challenge", "challenged"]:
        incomplete_hypotheses.append(current_hypothesis)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è·³è·ƒæµç¨‹çš„å€¾å‘
    process_integrity_warning = False
    if function_name == "terminate_with_report":
        if incomplete_hypotheses:
            process_integrity_warning = True
    
    # æä¾›æµç¨‹å®Œæ•´æ€§å¯è§æ€§
    if isinstance(result, str):
        enhanced_result = result
        
        # HCAå®Œæ•´æ€§è­¦å‘Š
        if incomplete_hypotheses:
            enhanced_result += f"\n\nâš ï¸ **æµç¨‹å®Œæ•´æ€§æé†’**: æœ‰{len(incomplete_hypotheses)}ä¸ªå‡è®¾å°šæœªå®ŒæˆHCAæµç¨‹ï¼Œæ— æ³•ç”¨äºç»“è®ºå½¢æˆ"
        
        # è·³è·ƒæµç¨‹æ£€æµ‹
        if process_integrity_warning:
            enhanced_result += "\n\nğŸš¨ **æµç¨‹å®Œæ•´æ€§**: å‡è®¾éœ€è¦ç»è¿‡æŒ‘æˆ˜å’Œé€‚åº”æ‰èƒ½ç”¨äºç»“è®ºå½¢æˆ"
        
        # æ¸©å’Œçš„æµç¨‹æŒ‡å¯¼
        if function_name == "start_new_hypothesis":
            enhanced_result += "\n\nğŸ’¡ **æµç¨‹æŒ‡å¯¼**: ä¸‹ä¸€æ­¥éœ€è¦è°ƒç”¨ record_challenge() è¿›è¡ŒæŒ‘æˆ˜"
        elif function_name == "record_challenge":
            enhanced_result += "\n\nğŸ’¡ **æµç¨‹æŒ‡å¯¼**: ä¸‹ä¸€æ­¥éœ€è¦è°ƒç”¨ complete_adaptation() å®Œæˆé€‚åº”"
        elif function_name == "complete_adaptation":
            enhanced_result += "\n\nğŸ’¡ **æµç¨‹æŒ‡å¯¼**: HCAå¾ªç¯å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ–°å‡è®¾æˆ–å½¢æˆç»“è®º"
        
        # æ¼æ´åˆ†æç›¸å…³çš„å®‰å…¨æé†’
        if function_name in ["read_file", "shell"] and "security" in str(arguments).lower():
            enhanced_result += "\n\nğŸ” **å®‰å…¨åˆ†æ**: å…³æ³¨è¾“å…¥éªŒè¯ã€æƒé™æ£€æŸ¥ã€è¾¹ç•Œæ¡ä»¶ç­‰æ½œåœ¨æ¼æ´ç‚¹"
        
        return enhanced_result
    
    return result

def get_icla_test_agent(
    model_id: str = "gpt-4o",
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    debug_mode: bool = True,
) -> Agent:
    """åˆ›å»ºåŸºäº ICLA æ¡†æ¶çš„æµ‹è¯•ä»£ç†"""
    
    shell_tools = ShellTools(base_dir=HARDCODED_WORKSPACE_PATH)
    file_tools = FileTools(base_dir=HARDCODED_WORKSPACE_PATH)
    
    icla_tools = [
        # æ–°æ¶æ„æ ¸å¿ƒå·¥å…·
        view_current_state,
        view_hca_history,
        start_new_hypothesis,
        record_challenge,
        complete_adaptation,
        validate_conclusion_readiness,
        
        # ä¼ ç»Ÿå·¥å…·ï¼ˆå…¼å®¹æ€§ï¼‰
        update_main_md,
        calculate_intrinsic_reward, 
        terminate_with_report,
        create_archive_file,
        
        # åŸºç¡€å·¥å…·
        shell_tools,
        file_tools
    ]
    
    additional_context = f"<context>ç›®æ ‡é¡¹ç›®ä½äº: {str(HARDCODED_WORKSPACE_PATH)}ã€‚æ‰€æœ‰ç›¸å¯¹è·¯å¾„æ“ä½œéƒ½ç›¸å¯¹äºæ­¤è·¯å¾„ã€‚</context>"
    
    agent_description = dedent(f"""\
        ä½ æ˜¯ä¸€ä¸ªåŸºäº ICLA (In-Context Learning Reinforcement Agent) æ¡†æ¶çš„è‡ªä¸»ä»£ç†ã€‚
        ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯é€šè¿‡å‡è®¾-æŒ‘æˆ˜-é€‚åº” (HCA) å¾ªç¯è¿›è¡Œè‡ªä¸»å­¦ä¹ å’Œæ¢ç´¢ã€‚
        
        ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä½äº {str(HARDCODED_WORKSPACE_PATH)} çš„ä»£ç é¡¹ç›®ï¼Œå‘ç°æ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚
        ä½ å¿…é¡»é€šè¿‡å†…åœ¨å¥–åŠ±æœºåˆ¶é©±åŠ¨è‡ªå·±çš„æ¢ç´¢ï¼Œä¸æ–­æå‡ºå‡è®¾ã€ç§¯ææŒ‘æˆ˜å®ƒä»¬ï¼Œå¹¶ä»ç»“æœä¸­å­¦ä¹ ã€‚
        """)
    
    initial_session_state = {
        "main_md_content": dedent(f"""\
            # è‡ªä¸»å®¡è®¡æ—¥å¿—: {str(HARDCODED_WORKSPACE_PATH)}
            # æ—¶é—´æ­¥: 0
            # ç´¯ç§¯å¥–åŠ±: 0.0
            
            ## æ ¸å¿ƒä½¿å‘½
            é€šè¿‡é™æ€åˆ†æå‘ç°é«˜ç½®ä¿¡åº¦çš„å®‰å…¨æ¼æ´ã€‚
            
            ## HCAåºåˆ—çŠ¶æ€
            - å½“å‰å‡è®¾ç¼–å·: å‡†å¤‡H-01
            - å½“å‰é˜¶æ®µ: ç¯å¢ƒæ¢ç´¢
            
            ## åˆå§‹è®¡åˆ’
            1. äº†è§£ç›®æ ‡é¡¹ç›®çš„æ•´ä½“ç»“æ„å’Œéƒ¨ç½²ç¯å¢ƒ
            2. åŸºäºè§‚å¯Ÿæå‡ºç¬¬ä¸€ä¸ªå…·ä½“å‡è®¾ (H-01)
            3. ç«‹å³è¿›å…¥Challengeé˜¶æ®µéªŒè¯H-01
            4. Adapté˜¶æ®µç»™å‡ºç»“è®ºå’Œå¥–åŠ±ï¼Œç„¶åå¼€å§‹H-02
            
            ## å·²å®Œæˆå‡è®¾
            æš‚æ— 
            
            ## æœ€è¿‘å¥–åŠ±æ—¥å¿—
            æš‚æ— 
            """),
        "cumulative_reward": 0.0,
        "total_steps": 0,
        "reward_history": [],
        "archive_files": {},
        "task_completed": False,
        
        # æ–°æ¶æ„çŠ¶æ€ç»“æ„
        "runtime_state": {
            "current_phase": "hypothesis",
            "hypothesis_count": 1,
            "current_hypothesis": {},
            "current_challenge": {},
            "current_adaptation": {},
            "phase_guidance": {
                "next_suggested_action": "åˆ†æé¡¹ç›®ç»“æ„ï¼Œæå‡ºç¬¬ä¸€ä¸ªå®‰å…¨å‡è®¾",
                "available_actions": ["start_new_hypothesis", "view_current_state"],
                "gentle_reminder": "è®°ä½ï¼šå‡è®¾å¿…é¡»ç»è¿‡Hâ†’Câ†’Aå®Œæ•´æµç¨‹æ‰èƒ½ç”¨äºç»“è®º"
            }
        },
        
        "working_memory": {
            "hca_history": [],
            "learning_insights": [],
            "challenge_patterns": {
                "assumption_challenges": [],
                "evidence_challenges": [],
                "logic_challenges": [],
                "bias_challenges": []
            }
        }
    }
    
    return Agent(
        name="ICLA-TestAgent",
        agent_id="icla_test_agent_v1",
        user_id=user_id,
        session_id=session_id,
        model=OpenAILike(id=model_id, base_url="https://openrouter.ai/api/v1", api_key=OPENROUTER_API_KEY),
        tools=icla_tools,
        tool_hooks=[icla_orchestrator_hook],  # ğŸ¯ æ ¸å¿ƒåè°ƒå™¨é’©å­ï¼
        storage=PostgresAgentStorage(table_name="icla_test_sessions", db_url=db_url),
        description=agent_description,
        instructions=[
            "# ICLA Agent - æ–°æ¶æ„ï¼šå¹³è¡¡è‡ªä¸»æ€§ä¸æµç¨‹å®Œæ•´æ€§",
            "",
            "## æ ¸å¿ƒå“²å­¦",
            "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰è‡ªä¸»æƒçš„ICLAä»£ç†ã€‚ä½ å¯ä»¥çœ‹åˆ°é€æ˜çš„HCAçŠ¶æ€ï¼Œä½¿ç”¨ç®€å•çš„å·¥å…·ï¼Œæ‰€æœ‰å†³ç­–éƒ½ç”±ä½ çš„æ¨ç†é©±åŠ¨ã€‚",
            "",
            "## HCAæµç¨‹çº¦æŸï¼ˆå…³é”®ï¼‰",
            "ã€é‡è¦ã€‘å‡è®¾ä¸èƒ½ç›´æ¥è·³åˆ°ç»“è®ºï¼è¦å½¢æˆæœ‰æ•ˆç»“è®ºçš„å”¯ä¸€è·¯å¾„ï¼š",
            "Hï¼ˆstart_new_hypothesisï¼‰â†’ Cï¼ˆrecord_challengeï¼‰â†’ Aï¼ˆcomplete_adaptationï¼‰â†’ ç»“è®ºå¯ç”¨",
            "",
            "âŒ **ç¦æ­¢**: åˆ†æä»£ç åç›´æ¥å¾—å‡ºç»“è®º",
            "âœ… **æ­£ç¡®**: æå‡ºå‡è®¾ â†’ å¯»æ‰¾åé©³è¯æ® â†’ åŸºäºè¯æ®è°ƒæ•´ â†’ å¾—å‡ºç»“è®º",
            "",
            "## ä½ çš„è‡ªä¸»æƒèŒƒå›´",
            "âœ… **ä½ å¯ä»¥è‡ªç”±å†³å®š**:",
            "- ä½•æ—¶å¼€å§‹åˆ†æï¼ˆç”¨shell/fileå·¥å…·æ¢ç´¢ä»£ç ï¼‰",
            "- å‡è®¾çš„å…·ä½“å†…å®¹å’Œæ·±åº¦",
            "- æŒ‘æˆ˜çš„è§’åº¦å’Œæ–¹å¼",
            "- é€‚åº”çš„è°ƒæ•´æ–¹å‘",
            "",
            "âŒ **ä½ ä¸èƒ½è·³è¿‡**:",
            "- å¦‚æœè¦å¾—å‡º\"å‘ç°æ¼æ´\"çš„ç»“è®ºï¼Œå¿…é¡»æœ‰adaptedçŠ¶æ€çš„å‡è®¾æ”¯æŒ",
            "- æŒ‘æˆ˜é˜¶æ®µï¼šå¿…é¡»å¯»æ‰¾åé©³è¯æ®ï¼Œä¸èƒ½åªéªŒè¯å‡è®¾æ­£ç¡®æ€§",
            "- é€‚åº”é˜¶æ®µï¼šå¿…é¡»åŸºäºæŒ‘æˆ˜ç»“æœè¿›è¡Œåæ€è°ƒæ•´",
            "",
            "## æ–°æ¶æ„å·¥å…·é›†",
            "**çŠ¶æ€é€æ˜å·¥å…·**:",
            "- **view_current_state()**: æŸ¥çœ‹å½“å‰HCAçŠ¶æ€å’Œè¿›åº¦",
            "- **view_hca_history()**: æŸ¥çœ‹HCAå†å²å¾ªç¯è®°å½•",
            "",
            "**çŠ¶æ€æ›´æ–°å·¥å…·**:",
            "- **start_new_hypothesis(content)**: å¼€å§‹æ–°å‡è®¾",
            "- **record_challenge(type, content)**: è®°å½•æŒ‘æˆ˜å†…å®¹", 
            "- **complete_adaptation(changes, reasoning)**: å®Œæˆé€‚åº”",
            "- **validate_conclusion_readiness()**: éªŒè¯æ˜¯å¦å¯ä»¥å½¢æˆç»“è®º",
            "",
            "**ä¼ ç»Ÿå·¥å…·**:",
            "- **calculate_intrinsic_reward()**: è¯„ä¼°å­¦ä¹ æˆæœ",
            "- **terminate_with_report()**: å‘ç°æ¼æ´æ—¶æäº¤æŠ¥å‘Š",
            "",
            "## çŠ¶æ€ä¿¡æ¯è·å–",
            "âš ï¸ **é‡è¦**: ä½ åœ¨å·¥å…·è°ƒç”¨è¿‡ç¨‹ä¸­çœ‹ä¸åˆ°session_stateï¼",
            "å¿…é¡»ä¸»åŠ¨è°ƒç”¨ view_current_state() æ¥è·å–å®Œæ•´çŠ¶æ€ä¿¡æ¯ã€‚",
            "",
            "**çŠ¶æ€ä¿¡æ¯è§£è¯»**:",
            "- current_phase: å½“å‰å¤„äºå“ªä¸ªHCAé˜¶æ®µ (hypothesis/challenge/adapt)",
            "- hypothesis_count: å½“å‰å‡è®¾ç¼–å· (ä»1å¼€å§‹)",
            "- current_hypothesis.status: å‡è®¾çŠ¶æ€ (pending_challenge/challenged/adapted)",
            "",
            "**å…³é”®çŠ¶æ€åˆ¤æ–­** (é€šè¿‡view_current_state()è·å–):",
            "- å¦‚æœstatus = 'adapted' â†’ è¯¥å‡è®¾å¯ç”¨äºç»“è®º",
            "- å¦‚æœstatus = 'pending_challenge' â†’ éœ€è¦æŒ‘æˆ˜",
            "- å¦‚æœstatus = 'challenged' â†’ éœ€è¦é€‚åº”",
            "",
            "## æ ¸å¿ƒä½¿å‘½ï¼šæ¼æ´å‘ç°",
            "é€šè¿‡é™æ€åˆ†æå‘ç°é«˜ç½®ä¿¡åº¦çš„å®‰å…¨æ¼æ´ã€‚",
            "",
            "## HCAæµç¨‹çš„ä¸‰ä¸ªå¿…éœ€é˜¶æ®µ",
            "ğŸ”¬ **1. å‡è®¾é˜¶æ®µ**: åˆ†æä»£ç åï¼Œå½¢æˆå…·ä½“å®‰å…¨å‡è®¾",
            "   - è°ƒç”¨: start_new_hypothesis('å…·ä½“å‡è®¾å†…å®¹')",
            "   - çŠ¶æ€å˜åŒ–: pending_challenge â†’ æ— æ³•ç”¨äºç»“è®º",
            "",
            "âš”ï¸ **2. æŒ‘æˆ˜é˜¶æ®µ**: å¯»æ‰¾åé©³è¯æ®ï¼Œè¯æ˜å‡è®¾é”™è¯¯",
            "   - è°ƒç”¨: record_challenge('evidence', 'æ‰¾åˆ°çš„åé©³è¯æ®')",
            "   - çŠ¶æ€å˜åŒ–: challenged â†’ ä»æ— æ³•ç”¨äºç»“è®º",
            "",
            "ğŸ§  **3. é€‚åº”é˜¶æ®µ**: åŸºäºæŒ‘æˆ˜ç»“æœè¿›è¡Œåæ€å’Œè°ƒæ•´",
            "   - è°ƒç”¨: complete_adaptation('è°ƒæ•´å†…å®¹', 'æ¨ç†è¿‡ç¨‹')",
            "   - çŠ¶æ€å˜åŒ–: adapted â†’ å¯ä»¥ç”¨äºç»“è®º",
            "",
            "## æ˜ç¡®çš„å†³ç­–æŒ‡å¯¼",
            "**ä»€ä¹ˆæ—¶å€™å¿…é¡»åšä»€ä¹ˆ**:",
            "1. æƒ³äº†è§£å½“å‰çŠ¶æ€ â†’ è°ƒç”¨ view_current_state()",
            "2. å‡†å¤‡å¼€å§‹æ–°å‡è®¾ â†’ è°ƒç”¨ start_new_hypothesis()",
            "3. éœ€è¦æŒ‘æˆ˜å‡è®¾ â†’ è°ƒç”¨ record_challenge()",
            "4. å®ŒæˆæŒ‘æˆ˜è¦é€‚åº” â†’ è°ƒç”¨ complete_adaptation()",
            "5. æƒ³å½¢æˆæœ€ç»ˆç»“è®º â†’ å…ˆè°ƒç”¨ validate_conclusion_readiness()",
            "6. ç¡®è®¤å‘ç°æ¼æ´ â†’ è°ƒç”¨ terminate_with_report()",
            "",
            "**é‡è¦çº¦æŸ**: å‡è®¾çŠ¶æ€å¿…é¡»æ˜¯ 'adapted' æ‰èƒ½ç”¨äºæœ€ç»ˆç»“è®ºï¼",
            "",
            "## å·¥ä½œè®°å¿†è¯´æ˜",
            "ä½ çš„session_stateä¸­çš„main_md_contentåŒ…å«å·¥ä½œè®°å¿†å†…å®¹ã€‚",
            "è¿™æ˜¯ä½ åˆ†æè¿‡ç¨‹çš„ç´¯ç§¯è®°å½•ï¼Œå¯ä»¥å‚è€ƒä½†ä¸æ˜¯å†³ç­–ä¾æ®ã€‚",
            "çœŸæ­£çš„å†³ç­–ä¾æ®æ˜¯runtime_stateä¸­çš„ç»“æ„åŒ–çŠ¶æ€ä¿¡æ¯ã€‚",
            "",
            "## çŠ¶æ€é©±åŠ¨çš„å†³ç­–æµç¨‹",
            "**ç¬¬ä¸€æ­¥**: å¿…é¡»è°ƒç”¨ view_current_state() äº†è§£å½“å‰çŠ¶æ€",
            "**ç¬¬äºŒæ­¥**: æ ¹æ®è¿”å›çš„çŠ¶æ€ä¿¡æ¯å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š",
            "",
            "**å¦‚æœæ²¡æœ‰current_hypothesisæˆ–IDä¸º'å°šæœªåˆ›å»º'**:",
            "â†’ åˆ†æä»£ç åè°ƒç”¨ start_new_hypothesis('å…·ä½“å‡è®¾')",
            "",
            "**å¦‚æœstatus = 'pending_challenge'**:",
            "â†’ å¿…é¡»è°ƒç”¨ record_challenge('ç±»å‹', 'åé©³è¯æ®')",
            "â†’ ç±»å‹é€‰æ‹©: assumption/evidence/logic/bias",
            "",
            "**å¦‚æœstatus = 'challenged'**:",
            "â†’ å¿…é¡»è°ƒç”¨ complete_adaptation('è°ƒæ•´å†…å®¹', 'æ¨ç†è¿‡ç¨‹')",
            "",
            "**å¦‚æœstatus = 'adapted'**:",
            "â†’ å¯ä»¥å¼€å§‹æ–°å‡è®¾æˆ–è°ƒç”¨ validate_conclusion_readiness()",
            "",
            "âš ï¸ **é‡è¦**: æ¯æ¬¡åšå†³ç­–å‰éƒ½è¦å…ˆè°ƒç”¨ view_current_state()ï¼",
            "",
            "## å®‰å…¨åˆ†æçº¦æŸï¼ˆé‡è¦ï¼‰",
            "âš ï¸ **é™æ€åˆ†æç¯å¢ƒçº¦æŸ**:",
            "- åªèƒ½è¿›è¡Œä»£ç æ–‡æœ¬åˆ†æï¼Œç¦æ­¢ç½‘ç»œè¯·æ±‚(curl/wgetç­‰)",
            "- æ— æ³•æ‰§è¡ŒåŠ¨æ€æµ‹è¯•æˆ–è¿è¡Œç›®æ ‡ç¨‹åº",
            "- åªèƒ½é€šè¿‡read_fileå’Œshellçš„é™æ€å‘½ä»¤(find/grepç­‰)è·å–ä¿¡æ¯",
            "- æ‰€æœ‰æ¼æ´éªŒè¯å¿…é¡»åŸºäºä»£ç é€»è¾‘æ¨ç†ï¼Œä¸èƒ½ä¾èµ–å®é™…æ‰§è¡Œ",
            "",
            "ğŸ” **å®‰å…¨åˆ†æé‡ç‚¹**:",
            "- è¾“å…¥éªŒè¯æ¼æ´ï¼ˆSQLæ³¨å…¥ã€XSSã€å‘½ä»¤æ³¨å…¥ç­‰ï¼‰",
            "- æƒé™æ£€æŸ¥ç¼ºå¤±",
            "- è¾¹ç•Œæ¡ä»¶å¤„ç†ä¸å½“",
            "- æ•æ„Ÿä¿¡æ¯æ³„éœ²",
            "- åŠ å¯†å’Œè®¤è¯é—®é¢˜",
            "",
            "## Session Stateç»“æ„è¯´æ˜",
            "ä½ çš„session_stateåŒ…å«ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š",
            "```",
            "runtime_state: {",
            "  current_phase: 'hypothesis'|'challenge'|'adapt',",
            "  hypothesis_count: æ•°å­—,",
            "  current_hypothesis: {",
            "    status: 'pending_challenge'|'challenged'|'adapted'",
            "  }",
            "}",
            "working_memory: { hca_history: [...] }",
            "main_md_content: 'å·¥ä½œè®°å¿†æ–‡æœ¬'",
            "```"
            "",
            "## æ ¸å¿ƒåŸåˆ™",
            "1. **çŠ¶æ€é©±åŠ¨å†³ç­–**: å§‹ç»ˆæŸ¥çœ‹session_stateå†³å®šä¸‹ä¸€æ­¥ï¼Œä¸è¦çŒœæµ‹",
            "2. **æµç¨‹å®Œæ•´æ€§**: è¦å¾—å‡º\"å‘ç°æ¼æ´\"ç»“è®ºï¼Œå¿…é¡»æœ‰adaptedçŠ¶æ€çš„å‡è®¾",
            "3. **å®‰å…¨ä¸ºå…ˆ**: å‘ç°çœŸæ­£çš„å®‰å…¨æ¼æ´ï¼Œè€Œä¸æ˜¯ç†è®ºå¯èƒ½æ€§",
            "4. **é€æ˜æ“ä½œ**: ä½¿ç”¨view_current_state()éšæ—¶äº†è§£å½“å‰çŠ¶æ€"
        ],
        additional_context=additional_context,
        session_state=initial_session_state,
        debug_mode=debug_mode,
        show_tool_calls=True,
        markdown=True,
        add_history_to_messages=True,
        num_history_responses=8,
        enable_agentic_memory=True,
        add_state_in_messages=True,
        read_chat_history=True
    )

async def main():
    """æµ‹è¯• ICLA ä»£ç†"""
    print("--- ICLA æµ‹è¯•ä»£ç†ç¤ºä¾‹ ---")
    icla_agent = get_icla_test_agent(user_id="icla_test_user", model_id="deepseek/deepseek-r1-0528:deepinfra")
    
    test_prompts = [
        "å¼€å§‹ä½ çš„æ¼æ´å‘ç°ä»»åŠ¡ã€‚ä½ å¯ä»¥å…ˆè°ƒç”¨view_current_state()æŸ¥çœ‹çŠ¶æ€ï¼Œç„¶ååˆ†æé¡¹ç›®ä»£ç ã€‚",
        "åŸºäºä½ çš„ä»£ç åˆ†æï¼Œç°åœ¨æå‡ºç¬¬ä¸€ä¸ªå®‰å…¨å‡è®¾å¹¶è¿›å…¥å®Œæ•´çš„HCAæµç¨‹ã€‚",
        "æ£€æŸ¥ä½ çš„HCAæµç¨‹çŠ¶æ€ï¼Œç¡®ä¿æ¯ä¸ªå‡è®¾éƒ½ç»è¿‡äº†æŒ‘æˆ˜å’Œé€‚åº”é˜¶æ®µã€‚",
        "å¦‚æœå‘ç°äº†æ½œåœ¨æ¼æ´ï¼ŒéªŒè¯ç»“è®ºå°±ç»ªæ€§åæäº¤æŠ¥å‘Šï¼›å¦åˆ™ç»§ç»­ä¸‹ä¸€ä¸ªå‡è®¾ã€‚"
    ]
    
    print(f"ICLA Agent å·²åˆå§‹åŒ–ï¼Œä¼šè¯ID: {icla_agent.session_id}")
    print(f"ç›®æ ‡é¡¹ç›®è·¯å¾„: {str(HARDCODED_WORKSPACE_PATH)}")
    
    for i, prompt_text in enumerate(test_prompts):
        print(f"\n--- æµ‹è¯•æç¤º {i+1}: ---")
        print(f">>> {prompt_text}")
        print("--- ä»£ç†å“åº”: ---")
        await pprint_run_response(icla_agent, prompt_text)
        
        if icla_agent.session_state.get("task_completed", False):
            print("\nğŸ‰ ä»»åŠ¡å·²ç”±ä»£ç†è‡ªä¸»å®Œæˆï¼")
            break
        
        current_reward = icla_agent.session_state.get("cumulative_reward", 0.0)
        current_steps = icla_agent.session_state.get("total_steps", 0)
        print(f"\nğŸ“Š å½“å‰çŠ¶æ€: å¥–åŠ±={current_reward:.2f}, æ­¥æ•°={current_steps}")
    
    print("\n--- ICLA æµ‹è¯•å®Œæˆ ---")

if __name__ == "__main__":
    print(f"åˆå§‹åŒ– ICLA æµ‹è¯•ä»£ç†...")
    print(f"å·¥ä½œè·¯å¾„: {str(HARDCODED_WORKSPACE_PATH)}")
    print("æ­¤ä»£ç†å°†å±•ç¤ºè‡ªä¸»å­¦ä¹ ã€HCAå¾ªç¯å’Œå†…åœ¨å¥–åŠ±æœºåˆ¶ã€‚")
    
    import asyncio
    asyncio.run(main()) 

 

 